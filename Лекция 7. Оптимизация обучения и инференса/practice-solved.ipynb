{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30674,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nos.environ.update({'CUDA_VISIBLE_DEVICES': '0'})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"! pip install peft\n! pip install jsonlines\n! pip install accelerate\n! pip install bitsandbytes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"! nvidia-smi","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Загружаем модель и токенизатор","metadata":{}},{"cell_type":"code","source":"import torch\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n\nmodel_path = \"openlm-research/open_llama_3b_v2\"\n\ntokenizer = AutoTokenizer.from_pretrained(model_path)\n\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_compute_dtype=torch.float16,\n    bnb_4bit_quant_type='nf4',\n    bnb_4bit_use_double_quant=True\n)\n\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_path,\n    use_cache=False,\n    torch_dtype=torch.float16,\n    quantization_config=bnb_config\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from peft import get_peft_model, LoraConfig, prepare_model_for_kbit_training\n\nlora_config = LoraConfig(\n    task_type='CAUSAL_LM',\n    r=1,\n    target_modules=['q_proj', 'v_proj'],\n    lora_dropout=0.05\n)\n\nmodel.gradient_checkpointing_enable()\nmodel = prepare_model_for_kbit_training(model)\nmodel.enable_input_require_grads()\n\nmodel = get_peft_model(model, lora_config)\n\nmodel.print_trainable_parameters()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'Number of parameters: {model.num_parameters()}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Попробуем что-нибудь сгенерировать","metadata":{}},{"cell_type":"code","source":"model.eval()\nmodel.cuda()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.train()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nfrom transformers import GenerationConfig\n\nprompt = '### Вопрос: Как приготовить суп?\\n\\n### Ответ:'\n\ntokens = tokenizer(prompt, return_tensors='pt')\n\noutputs = model.generate(\n    inputs=tokens['input_ids'].cuda(),\n    generation_config=GenerationConfig(\n        max_new_tokens=512,\n        do_sample=True,\n        temperature=0.5,\n        top_k=40,\n        top_p=0.8\n    )\n)\n\nprint(tokenizer.decode(outputs[0][len(tokens['input_ids'][0]):]).strip())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Готовим датасет для обучения и валидации","metadata":{}},{"cell_type":"code","source":"from datasets import load_dataset\ndataset = load_dataset('IlyaGusev/ru_turbo_alpaca')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class MyDataset:\n    def __init__(self, data):\n        self.data = data\n        \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, idx):\n        return {\n            'instruction': (self.data[idx]['instruction'] + '\\n' + self.data[idx]['input']).strip(),\n            'output': self.data[idx]['output'].strip()\n        }","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def collate_fn(data):\n    inputs, outputs = [], []\n    \n    for x in data:\n        inp = f'### Вопрос: {x[\"instruction\"]}\\n\\n### Ответ:'\n        input_ids = tokenizer(\n            inp,\n            add_special_tokens=True\n        )['input_ids']\n        label_ids = tokenizer(\n            x['output'] + tokenizer.eos_token,\n            add_special_tokens=False,\n            max_length=512,\n            truncation=True\n        )['input_ids']\n        inputs.append(torch.tensor(input_ids + label_ids))\n        outputs.append(torch.tensor([-100] * len(input_ids) + label_ids))\n        \n    input_ids = torch.nn.utils.rnn.pad_sequence(inputs, batch_first=True, padding_value=0)\n    labels = torch.nn.utils.rnn.pad_sequence(outputs, batch_first=True, padding_value=-100)\n        \n    return {\n        'input_ids': input_ids,\n        'labels': labels,\n        'attention_mask': input_ids.ne(0)\n    }","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = MyDataset([dataset['train'][i] for i in range(128)])\neval_dataset = MyDataset([dataset['train'][i] for i in range(128, 128+64)])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import Trainer, TrainingArguments","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_args = TrainingArguments(\n    output_dir='./output',\n    learning_rate=5e-4,\n    per_device_train_batch_size=8,\n    per_device_eval_batch_size=8,\n    num_train_epochs=1,\n    logging_steps=1,\n    save_strategy=\"no\",\n    report_to=\"none\",\n    warmup_ratio=0.0,\n    evaluation_strategy=\"steps\",\n    eval_steps=8,\n    remove_unused_columns=False,\n    gradient_checkpointing=True\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer = Trainer(\n    model,\n    train_args,\n    tokenizer=tokenizer,\n    train_dataset=train_dataset,\n    eval_dataset=eval_dataset,\n    data_collator=collate_fn\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"! nvidia-smi","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}