{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-03-05T20:06:55.613658Z",
     "iopub.status.busy": "2024-03-05T20:06:55.613269Z",
     "iopub.status.idle": "2024-03-05T20:06:56.006424Z",
     "shell.execute_reply": "2024-03-05T20:06:56.005252Z",
     "shell.execute_reply.started": "2024-03-05T20:06:55.613627Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/russianinappropriatemessages/Inappapropriate_messages.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T20:06:56.787232Z",
     "iopub.status.busy": "2024-03-05T20:06:56.786728Z",
     "iopub.status.idle": "2024-03-05T20:07:01.037066Z",
     "shell.execute_reply": "2024-03-05T20:07:01.036080Z",
     "shell.execute_reply.started": "2024-03-05T20:06:56.787201Z"
    }
   },
   "outputs": [],
   "source": [
    "# pip install transformers sentencepiece\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import seaborn as sns\n",
    "\n",
    "from datasets import load_dataset\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T20:07:03.015443Z",
     "iopub.status.busy": "2024-03-05T20:07:03.014525Z",
     "iopub.status.idle": "2024-03-05T20:07:04.055064Z",
     "shell.execute_reply": "2024-03-05T20:07:04.053923Z",
     "shell.execute_reply.started": "2024-03-05T20:07:03.015408Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"cointegrated/rubert-tiny\")\n",
    "model = AutoModel.from_pretrained(\"cointegrated/rubert-tiny\")\n",
    "# model.cuda()  # uncomment it if you have a GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T20:07:05.683775Z",
     "iopub.status.busy": "2024-03-05T20:07:05.682592Z",
     "iopub.status.idle": "2024-03-05T20:07:05.691535Z",
     "shell.execute_reply": "2024-03-05T20:07:05.690552Z",
     "shell.execute_reply.started": "2024-03-05T20:07:05.683740Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(29564, 312, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 312)\n",
       "    (token_type_embeddings): Embedding(2, 312)\n",
       "    (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-2): 3 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=312, out_features=312, bias=True)\n",
       "            (key): Linear(in_features=312, out_features=312, bias=True)\n",
       "            (value): Linear(in_features=312, out_features=312, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=312, out_features=312, bias=True)\n",
       "            (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=312, out_features=600, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=600, out_features=312, bias=True)\n",
       "          (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=312, out_features=312, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T20:07:07.135362Z",
     "iopub.status.busy": "2024-03-05T20:07:07.135014Z",
     "iopub.status.idle": "2024-03-05T20:07:07.156699Z",
     "shell.execute_reply": "2024-03-05T20:07:07.155756Z",
     "shell.execute_reply.started": "2024-03-05T20:07:07.135336Z"
    }
   },
   "outputs": [],
   "source": [
    "text = [\"LLM - смысл моей жизни\", \"Не знаю, как мне жить без LLM\"]\n",
    "t = tokenizer(text, padding=True, truncation=True, return_tensors='pt')\n",
    "with torch.no_grad():\n",
    "    inputs = {k: v.to(model.device) for k, v in t.items()}\n",
    "    model_output = model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T20:07:08.682039Z",
     "iopub.status.busy": "2024-03-05T20:07:08.681242Z",
     "iopub.status.idle": "2024-03-05T20:07:08.687384Z",
     "shell.execute_reply": "2024-03-05T20:07:08.686414Z",
     "shell.execute_reply.started": "2024-03-05T20:07:08.682005Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 ['[CLS]', 'LL', '##M', '-', 'см', '##ыс', '##л', 'м', '##ое', '##й', 'жизни', '[SEP]', '[PAD]']\n",
      "13 ['[CLS]', 'Не', 'з', '##на', '##ю', ',', 'как', 'мне', 'жить', 'без', 'LL', '##M', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "print(len(t[0].tokens), t[0].tokens)\n",
    "print(len(t[1].tokens), t[1].tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Padding\n",
    "\n",
    "Обратите внимание, что в конце каждого из двух предложений добавляется спецтокен [SEP] (даже без упоминания задачи NSP), а также в первом тексте добавлен токен [PAD]. Почему добавлен токен [PAD]?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T20:07:10.255524Z",
     "iopub.status.busy": "2024-03-05T20:07:10.254422Z",
     "iopub.status.idle": "2024-03-05T20:07:10.261962Z",
     "shell.execute_reply": "2024-03-05T20:07:10.260718Z",
     "shell.execute_reply.started": "2024-03-05T20:07:10.255485Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T20:07:11.306955Z",
     "iopub.status.busy": "2024-03-05T20:07:11.306263Z",
     "iopub.status.idle": "2024-03-05T20:07:11.314912Z",
     "shell.execute_reply": "2024-03-05T20:07:11.313663Z",
     "shell.execute_reply.started": "2024-03-05T20:07:11.306922Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    2,  9416,  1521,    17,  4159, 11654,   869,   324,  4427,   775,\n",
       "          4482,     3,     0],\n",
       "        [    2,  6226,   319,   794,   920,    16,  1150, 20284, 27162,  2399,\n",
       "          9416,  1521,     3]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T20:07:11.828203Z",
     "iopub.status.busy": "2024-03-05T20:07:11.827843Z",
     "iopub.status.idle": "2024-03-05T20:07:11.835649Z",
     "shell.execute_reply": "2024-03-05T20:07:11.834531Z",
     "shell.execute_reply.started": "2024-03-05T20:07:11.828175Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.token_type_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attention-маска определяет, какие токены будут использоваться для подсчета self-attention в каждом энкодер-блоке. В случае BERT мы игнорируем все [PAD]-токены в таких подсчетах, тк padding не несет никакой семантики и кол-во таких токенов зависит от размера контекста либо наиболее длинной последовательности в батче"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T20:07:23.888419Z",
     "iopub.status.busy": "2024-03-05T20:07:23.887605Z",
     "iopub.status.idle": "2024-03-05T20:07:23.896268Z",
     "shell.execute_reply": "2024-03-05T20:07:23.895088Z",
     "shell.execute_reply.started": "2024-03-05T20:07:23.888349Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.attention_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Выход модели BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T20:07:27.032498Z",
     "iopub.status.busy": "2024-03-05T20:07:27.031737Z",
     "iopub.status.idle": "2024-03-05T20:07:27.039012Z",
     "shell.execute_reply": "2024-03-05T20:07:27.037939Z",
     "shell.execute_reply.started": "2024-03-05T20:07:27.032461Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['last_hidden_state', 'pooler_output'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_output.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определите, какая размерность будет на выходе из последнего слоя данной BERT-модели при данном входе:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Shape выхода одного текста (первая размерность отвечает за batch_size, то есть кол-во текстов):\\n\\n\\t', model_output.last_hidden_state.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = model_output.last_hidden_state[:, 0, :]\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как правило, нейронные сети гораздо эффективнее обучаются, если подавать им на вход нормализованные данные. Поэтому BERT-эмбеддинги тоже часто нормализуют.\n",
    "\n",
    "Важно: нормализуем по размерности dim=1, которая соответствует компонентам одного эмбеддинга (то есть при подсчете mean и std используется эмбеддинг только одного текста)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = torch.nn.functional.normalize(embeddings)\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее в качестве эмбеддинга всего текста можем взять эмбеддинг [CLS]-токена"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = embeddings[0].cpu().numpy()\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - BERT для поиска похожих"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишем функцию, с помощью которой будем считать эмбеддинги для нескольких текстов одновременно - батчами (на гпу это значительно ускоорит подсчет эмбеддингов, можете проверить)\n",
    "\n",
    "В функции предусмотрено два режима mode: \n",
    "* 'cls' - в качестве текстового эмбеддинга используем эмбеддинг [CLS] токена с последнего слоя\n",
    "* 'mean' - в качестве текстового эмбеддинга используем усредненный эмбеддинг всех значимых токенов с последнего слоя. Незначимые токены - токены [PAD], которые мы не используем в усреденении. Обратите внимание, как мы используем маску mask для выделения из всех эмбеддингов эмбеддинги только значимых токенов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T20:07:42.233905Z",
     "iopub.status.busy": "2024-03-05T20:07:42.233506Z",
     "iopub.status.idle": "2024-03-05T20:07:42.243513Z",
     "shell.execute_reply": "2024-03-05T20:07:42.242460Z",
     "shell.execute_reply.started": "2024-03-05T20:07:42.233874Z"
    }
   },
   "outputs": [],
   "source": [
    "def embed_bert_cls(text_batch, model, tokenizer, mode):\n",
    "    t = tokenizer(text_batch, padding=True, truncation=True, return_tensors='pt')\n",
    "    with torch.no_grad():\n",
    "        model_output = model(**{k: v.to(model.device) for k, v in t.items()})\n",
    "        \n",
    "        embeddings = None\n",
    "        if mode == 'mean':\n",
    "            embeddings = []\n",
    "            for embs, mask in zip(model_output.last_hidden_state, t.attention_mask):\n",
    "                embeddings.append( embs[mask.type(torch.bool)].mean(0).cpu() )\n",
    "            embeddings = torch.stack(embeddings)\n",
    "        elif mode == 'cls':\n",
    "            embeddings = model_output.last_hidden_state[:, 0, :].cpu()\n",
    "        else:\n",
    "            raise ValueError('Unknown mode')\n",
    "    \n",
    "    return torch.nn.functional.normalize(embeddings, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Скачаем новостные статьи как в дз 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T20:07:43.809705Z",
     "iopub.status.busy": "2024-03-05T20:07:43.808947Z",
     "iopub.status.idle": "2024-03-05T20:07:43.816674Z",
     "shell.execute_reply": "2024-03-05T20:07:43.815428Z",
     "shell.execute_reply.started": "2024-03-05T20:07:43.809668Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_dataset(train_size: int,\n",
    "                test_size: int,\n",
    "                ds_name_1: str = 'IlyaGusev/gazeta',\n",
    "               ): \n",
    "    \n",
    "    train_dataset = load_dataset(ds_name_1, split='train')\n",
    "    test_dataset = load_dataset(ds_name_1, split='test')\n",
    "\n",
    "    train_df = pd.DataFrame(train_dataset).iloc[:train_size]\n",
    "    print(train_df.shape)\n",
    "\n",
    "    test_df = pd.DataFrame(test_dataset)[:test_size]\n",
    "    print(test_df.shape)\n",
    "\n",
    "    train_texts = (train_df['title'] + '\\n' + train_df['text']).tolist()\n",
    "    test_texts = (test_df['title'] + '\\n' + test_df['text']).tolist()\n",
    "    \n",
    "    return train_texts, test_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T20:07:45.495538Z",
     "iopub.status.busy": "2024-03-05T20:07:45.495185Z",
     "iopub.status.idle": "2024-03-05T20:07:55.446263Z",
     "shell.execute_reply": "2024-03-05T20:07:55.445238Z",
     "shell.execute_reply.started": "2024-03-05T20:07:45.495509Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 5)\n",
      "(1000, 5)\n"
     ]
    }
   ],
   "source": [
    "train_texts, test_texts = get_dataset(10_000, 1_000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оставим из новостей только заголовки для удобства их чтения (вам, ведь модель BERT вполне справится с чтением и всего текста) :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T20:09:17.185532Z",
     "iopub.status.busy": "2024-03-05T20:09:17.184800Z",
     "iopub.status.idle": "2024-03-05T20:09:17.196677Z",
     "shell.execute_reply": "2024-03-05T20:09:17.195591Z",
     "shell.execute_reply.started": "2024-03-05T20:09:17.185493Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['В Германии объяснили упоминание имени Путина на протестах в Берлине ',\n",
       " 'Делегации Израиля и США прибыли в ОАЭ для обсуждения соглашения о сотрудничестве ',\n",
       " 'Оппозиция Белоруссии объявила о создании новой партии «Вместе» ',\n",
       " 'Россия считает крайне опасными действия США на учениях в Эстонии ',\n",
       " 'В России вступил в силу закон о внесудебном банкротстве частных лиц ',\n",
       " '100 лет назад Красная армия под командованием Фрунзе взяла Бухару ',\n",
       " 'В ООН ответили Поклонской по вопросу о водной блокаде Крыма Украиной ',\n",
       " 'Умер детский писатель Владислав Крапивин ',\n",
       " 'Минобороны РФ опровергло заявление НАТО о нарушении датских границ ',\n",
       " 'Трамп предрек революцию в Америке в случае победы Байдена ',\n",
       " 'Врачи предупредили об опасности ожирения при COVID-19 ',\n",
       " 'Помпео указал на рост активности военных РФ в различных регионах мира ',\n",
       " 'CNBC: решение о продаже TikTok примут в ближайшие сутки ',\n",
       " 'Лавров призвал Запад не навязывать Белоруссии «посреднические услуги» ',\n",
       " 'Депардье вспомнил, как Путин прислал за ним самолет ']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_headlines = list(map(lambda w: w.split('\\n')[0], test_texts))\n",
    "test_headlines[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как мы видим, новости во многом про политику, реже встречаются другие темы, например, про ковид:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T20:09:18.710395Z",
     "iopub.status.busy": "2024-03-05T20:09:18.710004Z",
     "iopub.status.idle": "2024-03-05T20:09:18.716615Z",
     "shell.execute_reply": "2024-03-05T20:09:18.715393Z",
     "shell.execute_reply.started": "2024-03-05T20:09:18.710353Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Врачи предупредили об опасности ожирения при COVID-19 '"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_headlines[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подгрузим небольшую BERT-модель, чтобы быстро предподсчитать эмбеддинги. Далее мы будем использовать BERT как экстрактор семантических признаков из текста, т.е. с помощью BERT мы переведем текст в вектор в некотором пространстве, в котором в идеале семантически похожие тексты должны лежать близко друг к другу, а непохожие - далеко.\n",
    "\n",
    "rubert-tiny - небольшая дистиллированая BERT-модель (вспоминаем DistillBERT, который обсуждали на лекции), которая обучалась преимущественно на русскоязычном корпусе (то есть домен - тексты на русском языке). Подробности модели можете посмотреть на hugginface в карточке модели:\n",
    "\n",
    "https://huggingface.co/cointegrated/rubert-tiny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T20:09:21.327903Z",
     "iopub.status.busy": "2024-03-05T20:09:21.327388Z",
     "iopub.status.idle": "2024-03-05T20:09:21.796518Z",
     "shell.execute_reply": "2024-03-05T20:09:21.795511Z",
     "shell.execute_reply.started": "2024-03-05T20:09:21.327870Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(29564, 312, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 312)\n",
       "    (token_type_embeddings): Embedding(2, 312)\n",
       "    (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-2): 3 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=312, out_features=312, bias=True)\n",
       "            (key): Linear(in_features=312, out_features=312, bias=True)\n",
       "            (value): Linear(in_features=312, out_features=312, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=312, out_features=312, bias=True)\n",
       "            (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=312, out_features=600, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=600, out_features=312, bias=True)\n",
       "          (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=312, out_features=312, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_MAX_LENGTH = 512 # длина контекста, можно взять из конфига модели-учителя: https://huggingface.co/google-bert/bert-base-multilingual-cased/blob/main/config.json\n",
    "\n",
    "rubert_tokenizer = AutoTokenizer.from_pretrained(\"cointegrated/rubert-tiny\")\n",
    "rubert_model = AutoModel.from_pretrained(\"cointegrated/rubert-tiny\")\n",
    "\n",
    "# rubert_tokenizer = AutoTokenizer.from_pretrained(\"ai-forever/ruBert-large\", model_max_length=MODEL_MAX_LENGTH)\n",
    "# rubert_model = AutoModel.from_pretrained(\"ai-forever/ruBert-large\")\n",
    "\n",
    "rubert_model.cuda() # иначе слишком долго считать"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T20:09:23.953600Z",
     "iopub.status.busy": "2024-03-05T20:09:23.953233Z",
     "iopub.status.idle": "2024-03-05T20:09:23.960569Z",
     "shell.execute_reply": "2024-03-05T20:09:23.959152Z",
     "shell.execute_reply.started": "2024-03-05T20:09:23.953574Z"
    }
   },
   "outputs": [],
   "source": [
    "TEXT_BATCH_SIZE = 64 # по 64 текста одновременно прогоняем через BERT\n",
    "\n",
    "def precalc_embeddings(texts, model, tokenizer, mode):\n",
    "    embeddings = []\n",
    "    for start_num in tqdm(range(0, len(texts), TEXT_BATCH_SIZE)):\n",
    "        text_batch = texts[start_num: start_num + TEXT_BATCH_SIZE]\n",
    "        emb_output = embed_bert_cls(text_batch, model, tokenizer, mode = mode)\n",
    "        embeddings.append(emb_output)\n",
    "\n",
    "    embeddings = np.concatenate(embeddings)\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T20:09:25.236617Z",
     "iopub.status.busy": "2024-03-05T20:09:25.235748Z",
     "iopub.status.idle": "2024-03-05T20:09:30.431686Z",
     "shell.execute_reply": "2024-03-05T20:09:30.430694Z",
     "shell.execute_reply.started": "2024-03-05T20:09:25.236583Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a3cd385246248068c1c6805599ae9f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embeddings = precalc_embeddings(test_texts, rubert_model, rubert_tokenizer, mode='cls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T20:09:30.433914Z",
     "iopub.status.busy": "2024-03-05T20:09:30.433561Z",
     "iopub.status.idle": "2024-03-05T20:09:30.440575Z",
     "shell.execute_reply": "2024-03-05T20:09:30.439557Z",
     "shell.execute_reply.started": "2024-03-05T20:09:30.433887Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Врачи предупредили об опасности ожирения при COVID-19 '"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos = 10\n",
    "test_headlines[pos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T20:09:30.442005Z",
     "iopub.status.busy": "2024-03-05T20:09:30.441734Z",
     "iopub.status.idle": "2024-03-05T20:09:30.458231Z",
     "shell.execute_reply": "2024-03-05T20:09:30.457060Z",
     "shell.execute_reply.started": "2024-03-05T20:09:30.441981Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1000)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sims = cosine_similarity(embeddings[pos][None, :], embeddings) #embeddings[pos + 1:])\n",
    "sims.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T20:09:30.461995Z",
     "iopub.status.busy": "2024-03-05T20:09:30.460794Z",
     "iopub.status.idle": "2024-03-05T20:09:30.470591Z",
     "shell.execute_reply": "2024-03-05T20:09:30.469422Z",
     "shell.execute_reply.started": "2024-03-05T20:09:30.461947Z"
    }
   },
   "outputs": [],
   "source": [
    "most_similar = sorted( list(zip(sims[0], np.arange(sims.shape[1]))) , reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T20:09:31.680458Z",
     "iopub.status.busy": "2024-03-05T20:09:31.679779Z",
     "iopub.status.idle": "2024-03-05T20:09:31.686798Z",
     "shell.execute_reply": "2024-03-05T20:09:31.685794Z",
     "shell.execute_reply.started": "2024-03-05T20:09:31.680426Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0000002, 10)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_similar[0] # естественно, самый близкий текст к исходному - это исходный текст, поэтому его игнорируем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Исходный текст:', test_headlines[pos], '\\n')\n",
    "\n",
    "print('Самые похожие тексты:\\n')\n",
    "for score, index in most_similar[1:5]:\n",
    "    print(f\"Sim={score} \\t\\t {test_headlines[index]}\")\n",
    "    \n",
    "print('\\n', '=' * 30, '\\n')\n",
    "\n",
    "print('Самые непохожие тексты:\\n')\n",
    "for score, index in most_similar[-5:]:\n",
    "    print(f\"Sim={score} \\t\\t {test_headlines[index]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T16:53:19.252781Z",
     "iopub.status.busy": "2024-03-05T16:53:19.252326Z",
     "iopub.status.idle": "2024-03-05T16:53:19.260810Z",
     "shell.execute_reply": "2024-03-05T16:53:19.259115Z",
     "shell.execute_reply.started": "2024-03-05T16:53:19.252744Z"
    }
   },
   "source": [
    "Определите текст, наиболее похожий на исходный текст, с помощью кода ниже. В качестве ответа приведете текст, заключенный внутри знаков знаки <>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( f'Ответ: <{test_headlines[most_similar[1][1]].strip()}>' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При том, что в тексте большая часть заголовков про политику, с помощью BERT-эмбеддингов мы без труда нашли несколько текстов, похожих на исходный - по тематике ковида"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Аналогично можно усреднять выходные эмбеддинги (не считая pad-токена). В данном случае, результат будет похожий (но заметьте, что при этом топ-5 отличается).\n",
    "\n",
    "Качество при разных способах получения эмбеддингов в данном случае особо не меняется из-за того, что [CLS] токен в исходной модели (учителе) обучался на задачу NSP. Если бы мы имели дело с RoBERT-a подобной моделью, то эмбеддинг [CLS]-токена из последнего слоя извлекал бы \"более рандомные\" признаки - ведь он ни на что не обучался во время претрейна, поэтому этот эмбеддинг агрегирует в себе эмбеддинги всех токенов из предпоследнего слоя (вспомните как работает self-attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = precalc_embeddings(test_texts, rubert_model, rubert_tokenizer, mode='mean')\n",
    "\n",
    "pos = 10\n",
    "sims = cosine_similarity(embeddings[pos][None, :], embeddings) #embeddings[pos + 1:])\n",
    "most_similar = sorted( list(zip(sims[0], np.arange(sims.shape[1]))) , reverse=True)\n",
    "\n",
    "print('Исходный текст:', test_headlines[pos], '\\n')\n",
    "\n",
    "print('Самые похожие тексты:\\n')\n",
    "for score, index in most_similar[1:5]:\n",
    "    print(f\"Sim={score} \\t\\t {test_headlines[index]}\")\n",
    "    \n",
    "print('\\n', '=' * 30, '\\n')\n",
    "\n",
    "print('Самые непохожие тексты:\\n')\n",
    "for score, index in most_similar[-5:]:\n",
    "    print(f\"Sim={score} \\t\\t {test_headlines[index]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - важность домена, на котором обучалась претрейн-модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T20:10:07.463481Z",
     "iopub.status.busy": "2024-03-05T20:10:07.463070Z",
     "iopub.status.idle": "2024-03-05T20:10:07.468337Z",
     "shell.execute_reply": "2024-03-05T20:10:07.467291Z",
     "shell.execute_reply.started": "2024-03-05T20:10:07.463450Z"
    }
   },
   "outputs": [],
   "source": [
    "del model\n",
    "del rubert_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T20:10:08.933070Z",
     "iopub.status.busy": "2024-03-05T20:10:08.932704Z",
     "iopub.status.idle": "2024-03-05T20:10:09.505193Z",
     "shell.execute_reply": "2024-03-05T20:10:09.503869Z",
     "shell.execute_reply.started": "2024-03-05T20:10:08.933043Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at FacebookAI/roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RobertaModel(\n",
       "  (embeddings): RobertaEmbeddings(\n",
       "    (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "    (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "    (token_type_embeddings): Embedding(1, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): RobertaEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): RobertaPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_MAX_LENGTH = 512 # длина контекста, можно взять из конфига модели-учителя: https://huggingface.co/google-bert/bert-base-multilingual-cased/blob/main/config.json\n",
    "\n",
    "en_roberta_tokenizer = AutoTokenizer.from_pretrained('FacebookAI/roberta-base')\n",
    "en_roberta_model = AutoModel.from_pretrained('FacebookAI/roberta-base')\n",
    "\n",
    "en_roberta_model.cuda() # иначе слишком долго считать"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = precalc_embeddings(test_texts, en_roberta_model, en_roberta_tokenizer, mode='cls')\n",
    "\n",
    "pos = 10\n",
    "sims = cosine_similarity(embeddings[pos][None, :], embeddings)\n",
    "most_similar = sorted( list(zip(sims[0], np.arange(sims.shape[1]))) , reverse=True)\n",
    "\n",
    "print('Исходный текст:', test_headlines[pos], '\\n')\n",
    "\n",
    "print('Самые похожие тексты:\\n')\n",
    "for score, index in most_similar[1:5]:\n",
    "    print(f\"Sim={score} \\t\\t {test_headlines[index]}\")\n",
    "    \n",
    "print('\\n', '=' * 30, '\\n')\n",
    "\n",
    "print('Самые непохожие тексты:\\n')\n",
    "for score, index in most_similar[-5:]:\n",
    "    print(f\"Sim={score} \\t\\t {test_headlines[index]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = precalc_embeddings(test_texts, en_roberta_model, en_roberta_tokenizer, mode='mean')\n",
    "\n",
    "pos = 10\n",
    "sims = cosine_similarity(embeddings[pos][None, :], embeddings)\n",
    "most_similar = sorted( list(zip(sims[0], np.arange(sims.shape[1]))) , reverse=True)\n",
    "\n",
    "print('Исходный текст:', test_headlines[pos], '\\n')\n",
    "\n",
    "print('Самые похожие тексты:\\n')\n",
    "for score, index in most_similar[1:5]:\n",
    "    print(f\"Sim={score} \\t\\t {test_headlines[index]}\")\n",
    "    \n",
    "print('\\n', '=' * 30, '\\n')\n",
    "\n",
    "print('Самые непохожие тексты:\\n')\n",
    "for score, index in most_similar[-5:]:\n",
    "    print(f\"Sim={score} \\t\\t {test_headlines[index]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определите текст, наиболее похожий на исходный текст, с помощью кода ниже (используйте режим \"mean\" при подсчете эмбеддингов). В качестве ответа приведете текст, заключенный внутри знаков знаки <>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( f'Ответ: <{test_headlines[most_similar[1][1]].strip()}>' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как мы видим, тексты не то чтобы похожи, хотя датасет тот же самый. Это связано с тем, что RoBERTa, загруженная выше, обучалась на другом домене (преимущественно на англоязычных текстах), из-за чего на домене русскоязычных текстов эмбеддинги получаются так себе.\n",
    "\n",
    "Попробуем перевести самые похожие тексты для rubert-tiny и для roberta с русского на английский, и попробуем теперь посмотреть, какие тексты окажутся похожими"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T20:11:24.599430Z",
     "iopub.status.busy": "2024-03-05T20:11:24.598787Z",
     "iopub.status.idle": "2024-03-05T20:11:24.691418Z",
     "shell.execute_reply": "2024-03-05T20:11:24.690420Z",
     "shell.execute_reply.started": "2024-03-05T20:11:24.599365Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77ae5ba77b2a433a94eed5329cf5bce0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Исходный текст: Doctors warned of the dangers of obesity in COVID-19 \n",
      "\n",
      "Самые похожие тексты:\n",
      "\n",
      "Sim=0.9816614985466003 \t\t Scientists told about the danger of coronavirus for pregnant women\n",
      "Sim=0.9793349504470825 \t\t A new dangerous consequence of COVID-19 has been discovered\n",
      "Sim=0.977390706539154 \t\t A factor significantly reducing mortality from COVID-19 has been named\n",
      "Sim=0.9762434959411621 \t\t Scientists: glasses wearers suffer from COVID-19 five times less often\n",
      "\n",
      " ============================== \n",
      "\n",
      "Самые непохожие тексты:\n",
      "\n",
      "Sim=0.9704751372337341 \t\t Pamfilova announced the full readiness of the electoral system for the elections\n",
      "Sim=0.9676637053489685 \t\t The programmer launched Doom and Skyrim on a pregnancy test\n",
      "Sim=0.9599279165267944 \t\t The Ministry of Defense has revealed details of joint exercises between Russia and Belarus\n",
      "Sim=0.959205687046051 \t\t The EU has agreed to expand the list of sanctions against the Russian Federation for the Crimean Bridge\n",
      "Sim=0.956506609916687 \t\t Roscosmos has agreed with a private firm to build a competitor to Musk's ship\n"
     ]
    }
   ],
   "source": [
    "translated_news = [\n",
    "\"The EU has agreed to expand the list of sanctions against the Russian Federation for the Crimean Bridge\",\n",
    "\"Roscosmos has agreed with a private firm to build a competitor to Musk's ship\",\n",
    "\"The Ministry of Defense has revealed details of joint exercises between Russia and Belarus\",\n",
    "\"Pamfilova announced the full readiness of the electoral system for the elections\",\n",
    "\"The programmer launched Doom and Skyrim on a pregnancy test\",\n",
    "\n",
    "\"Doctors warned of the dangers of obesity in COVID-19\",\n",
    "\"A factor significantly reducing mortality from COVID-19 has been named\",\n",
    "\"Scientists: glasses wearers suffer from COVID-19 five times less often\",\n",
    "\"Scientists told about the danger of coronavirus for pregnant women\",\n",
    "\"A new dangerous consequence of COVID-19 has been discovered\"\n",
    "]\n",
    "\n",
    "test_headlines = translated_news\n",
    "\n",
    "embeddings = precalc_embeddings(test_headlines, en_roberta_model, en_roberta_tokenizer, mode='mean')\n",
    "\n",
    "pos = 5\n",
    "sims = cosine_similarity(embeddings[pos][None, :], embeddings) #embeddings[pos + 1:])\n",
    "most_similar = sorted( list(zip(sims[0], np.arange(sims.shape[1]))) , reverse=True)\n",
    "\n",
    "print('Исходный текст:', test_headlines[pos], '\\n')\n",
    "\n",
    "print('Самые похожие тексты:\\n')\n",
    "for score, index in most_similar[1:5]:\n",
    "    print(f\"Sim={score} \\t\\t {test_headlines[index]}\")\n",
    "    \n",
    "print('\\n', '=' * 30, '\\n')\n",
    "\n",
    "print('Самые непохожие тексты:\\n')\n",
    "for score, index in most_similar[-5:]:\n",
    "    print(f\"Sim={score} \\t\\t {test_headlines[index]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь самые похожие тексты действительно похожи на исходный - потому что рабоатет в том же домене, в котором обучаласт претрейн-модель"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 - finetuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве датасета возьмем датасет неуместных запросов на русском языке (120к текстов). 1 - запрос неуместный, 0 - уместный.\n",
    "\n",
    "Датасет: https://www.kaggle.com/datasets/nigula/russianinappropriatemessages\n",
    "\n",
    "Можно добавить этот датасет в Kaggle через \"add input\" в правой панели, либо просто скачать и поменять путь к нему в коде ниже.\n",
    "\n",
    "Будем решать важную задачу фильтрации запросов для генеративных моделей - фильтрация некорректных запросов. Отвечать на такие запросы с помощью генеративной модели опасно - можно навредить пользователю, поэтому задача - отбивать подобные запросы с помощью классификатора."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ниже описана подготовка данных, а также инициализация токенизатора и BERT-модели - всё как на семинаре."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T20:11:32.927220Z",
     "iopub.status.busy": "2024-03-05T20:11:32.926262Z",
     "iopub.status.idle": "2024-03-05T20:11:35.578765Z",
     "shell.execute_reply": "2024-03-05T20:11:35.577922Z",
     "shell.execute_reply.started": "2024-03-05T20:11:32.927184Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-05 20:11:33.334901: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-05 20:11:33.334961: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-05 20:11:33.336506: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import transformers\n",
    "import torch.nn as nn\n",
    "from transformers import AutoModel, BertTokenizer, BertForSequenceClassification\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from datasets import load_metric, Dataset\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns \n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T20:11:35.580532Z",
     "iopub.status.busy": "2024-03-05T20:11:35.580209Z",
     "iopub.status.idle": "2024-03-05T20:11:37.108150Z",
     "shell.execute_reply": "2024-03-05T20:11:37.107095Z",
     "shell.execute_reply.started": "2024-03-05T20:11:35.580505Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_146707/1230382672.py:5: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  sns.distplot(df['inappropriate'])\n",
      "/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='inappropriate', ylabel='Density'>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_path = '/kaggle/input/russianinappropriatemessages/Inappapropriate_messages.csv'\n",
    "\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "sns.distplot(df['inappropriate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T20:11:37.110237Z",
     "iopub.status.busy": "2024-03-05T20:11:37.109918Z",
     "iopub.status.idle": "2024-03-05T20:11:37.618766Z",
     "shell.execute_reply": "2024-03-05T20:11:37.617853Z",
     "shell.execute_reply.started": "2024-03-05T20:11:37.110209Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_path)\n",
    "df.rename({'inappropriate': 'target'}, axis=1, inplace=True)\n",
    "df['target'] = (df['target'] >= 0.5).astype(int)\n",
    "\n",
    "TEST_SIZE = 0.2\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=TEST_SIZE)\n",
    "\n",
    "train_df.reset_index(drop=True, inplace=True)\n",
    "test_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "train_text = train_df['text'].astype(str)\n",
    "train_labels = train_df['target']\n",
    "\n",
    "test_text = test_df['text'].astype(str)\n",
    "test_labels = test_df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T20:11:37.620214Z",
     "iopub.status.busy": "2024-03-05T20:11:37.619903Z",
     "iopub.status.idle": "2024-03-05T20:11:37.629675Z",
     "shell.execute_reply": "2024-03-05T20:11:37.628664Z",
     "shell.execute_reply.started": "2024-03-05T20:11:37.620189Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    91448\n",
       "1    33149\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T20:11:37.632876Z",
     "iopub.status.busy": "2024-03-05T20:11:37.631846Z",
     "iopub.status.idle": "2024-03-05T20:11:37.641600Z",
     "shell.execute_reply": "2024-03-05T20:11:37.640659Z",
     "shell.execute_reply.started": "2024-03-05T20:11:37.632842Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99677, 99677, 24920, 24920)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_text), len(train_labels), len(test_text), len(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T20:11:37.642989Z",
     "iopub.status.busy": "2024-03-05T20:11:37.642707Z",
     "iopub.status.idle": "2024-03-05T20:13:08.747272Z",
     "shell.execute_reply": "2024-03-05T20:13:08.746313Z",
     "shell.execute_reply.started": "2024-03-05T20:11:37.642954Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99677 24920\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('cointegrated/rubert-tiny2')\n",
    "\n",
    "\n",
    "seq_len_train = [len(str(i).split()) for i in train_df['text']]\n",
    "seq_len_test = [len(str(i).split()) for i in test_df['text']]\n",
    "max_seq_len = min(512, max(max(seq_len_test), max(seq_len_train)))\n",
    "max_seq_len\n",
    "\n",
    "\n",
    "tokens_train = tokenizer.batch_encode_plus(\n",
    "    train_text.values,\n",
    "    max_length = max_seq_len,\n",
    "    padding = 'max_length',\n",
    "    truncation = True\n",
    ")\n",
    "\n",
    "tokens_test = tokenizer.batch_encode_plus(\n",
    "    test_text.values,\n",
    "    max_length = max_seq_len,\n",
    "    padding = 'max_length',\n",
    "    truncation = True\n",
    ")\n",
    "\n",
    "\n",
    "class Data(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
    "        item[\"labels\"] = torch.tensor([self.labels[idx]])\n",
    "        return item\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "train_dataset = Data(tokens_train, train_labels)\n",
    "test_dataset = Data(tokens_test, test_labels)\n",
    "\n",
    "print(len(train_dataset), len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T20:13:08.749456Z",
     "iopub.status.busy": "2024-03-05T20:13:08.749146Z",
     "iopub.status.idle": "2024-03-05T20:13:08.754828Z",
     "shell.execute_reply": "2024-03-05T20:13:08.753844Z",
     "shell.execute_reply.started": "2024-03-05T20:13:08.749430Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    f1 = f1_score(labels, preds)\n",
    "    return {'F1': f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T20:13:08.756488Z",
     "iopub.status.busy": "2024-03-05T20:13:08.756172Z",
     "iopub.status.idle": "2024-03-05T20:13:08.767573Z",
     "shell.execute_reply": "2024-03-05T20:13:08.766620Z",
     "shell.execute_reply.started": "2024-03-05T20:13:08.756454Z"
    }
   },
   "outputs": [],
   "source": [
    "# для воспроизводимости результатов\n",
    "def seed_all(seed_value):\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed_value)\n",
    "        torch.cuda.manual_seed_all(seed_value)\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "        torch.backends.cudnn.deterministic = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Берем предобученную русскоязычную модель и с помощью hugginface запускаем дообучение под нашу целевую задачу. Обучаем 1 эпоху, чтобы убедиться что всё работает. В Kaggle одна эпоха проходит примерно за 20 минут. Hugginface в процессе обучения рисует после каждой эпохи табличку, в которой показываем качество модели на данном этапе. В данном случае в качестве метрики мы используем f1-score в задаче бинарной классификации, поставленной выше."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T18:34:00.462227Z",
     "iopub.status.busy": "2024-03-05T18:34:00.461910Z",
     "iopub.status.idle": "2024-03-05T18:51:23.167411Z",
     "shell.execute_reply": "2024-03-05T18:51:23.166442Z",
     "shell.execute_reply.started": "2024-03-05T18:34:00.462202Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cointegrated/rubert-tiny2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6230' max='6230' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6230/6230 17:18, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.436800</td>\n",
       "      <td>0.387233</td>\n",
       "      <td>0.654412</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory ./results/checkpoint-6230 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=6230, training_loss=0.4368267910438403, metrics={'train_runtime': 1040.7025, 'train_samples_per_second': 95.779, 'train_steps_per_second': 5.986, 'total_flos': 735038828746752.0, 'train_loss': 0.4368267910438403, 'epoch': 1.0})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained('cointegrated/rubert-tiny2', num_labels=2).to(\"cuda\")\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir = './results', #Выходной каталог\n",
    "    num_train_epochs = 1, # 3, #Кол-во эпох для обучения\n",
    "    per_device_train_batch_size = 8, #Размер батча для каждого устройства во время обучения\n",
    "    per_device_eval_batch_size = 8, #Размер батча для каждого устройства во время валидации\n",
    "    weight_decay = 0.01, # регуляризация\n",
    "    logging_dir = './logs', # Каталог для хранения логов\n",
    "    report_to = 'tensorboard',\n",
    "    load_best_model_at_end = True, # Загружать ли лучшую модель после обучения\n",
    "    learning_rate = 1e-5, # Скорость обучения\n",
    "    evaluation_strategy ='epoch', #Валидация после каждой эпохи (можно сделать после конкретного кол-ва шагов)\n",
    "    logging_strategy = 'epoch', #Логирование после каждой эпохи\n",
    "    save_strategy = 'epoch', #Сохранение после каждой эпохи\n",
    "    save_total_limit = 1,\n",
    "    seed=42)\n",
    "\n",
    "\n",
    "seed_all(42)\n",
    "\n",
    "trainer = Trainer(model=model,\n",
    "                  tokenizer = tokenizer,\n",
    "                  args = training_args,\n",
    "                  train_dataset = train_dataset,\n",
    "                  eval_dataset = train_dataset,\n",
    "                  compute_metrics = compute_metrics)\n",
    "\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T18:51:23.168876Z",
     "iopub.status.busy": "2024-03-05T18:51:23.168586Z",
     "iopub.status.idle": "2024-03-05T18:51:23.173335Z",
     "shell.execute_reply": "2024-03-05T18:51:23.172396Z",
     "shell.execute_reply.started": "2024-03-05T18:51:23.168851Z"
    }
   },
   "outputs": [],
   "source": [
    "del model # освободим память и переинициализируем модель, чтобы точно не перепутать"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дообучите модель с параметрами ниже. Из нового - обучаем 3 эпохи вместо одной и с большим batch_size. \n",
    "\n",
    "Во время обучения трейнер hugginface отрисовывает таблицу с метриками прсле каждой эпохи. В качестве ответа укажите значение метрики f1 после третьей эпохи, округлив его до третьего знака после запятой с помощью функции round(..., 3). \n",
    "\n",
    "Погрешность ответа в проверяющей системе учитывает возможную случайность, возникающую при обучении. Если вы всё сделали правильно, то ответ, который вы введете, будет засчитан системой как верный."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertForSequenceClassification.from_pretrained('cointegrated/rubert-tiny2', num_labels=2).to(\"cuda\")\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    num_train_epochs = 3, # 3, #Кол-во эпох для обучения\n",
    "    per_device_train_batch_size = 16, #Размер батча для каждого устройства во время обучения\n",
    "    per_device_eval_batch_size = 16, #Размер батча для каждого устройства во время валидации\n",
    "    seed=42\n",
    "    ...\n",
    ") # заполните остальные параметры как в примере выше\n",
    "\n",
    "\n",
    "seed_all(42)\n",
    "\n",
    "trainer = Trainer( ... ) # заполните как в примере выше\n",
    "\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Если вам было мало моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тут в посте сделал короткую шпаргалку с ключевыми идеями других трансформерных моделей и их нововведениями относительно оригинального BERT-а. Может быть полезно, чтобы подчерпнуть идеи для собственных моделей либо вспомнить в общих чертах материал перед собеседованиями :) \n",
    "\n",
    "https://t.me/skeptical_research/27"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Не забывайте ставить звезды на гитхабе и оставлять обратную связь по лекции и дз!"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 1221604,
     "sourceId": 5341757,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30665,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
