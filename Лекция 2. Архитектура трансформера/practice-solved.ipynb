{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617d9d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "from torch.nn import Linear, Module, LayerNorm, Dropout, ReLU, Embedding, ModuleList, CrossEntropyLoss\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e34d7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b10fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention(queries, keys, values, Q, K, V, mask=None):\n",
    "    # queries, keys and values have dimensions: (batch_size, length, emb_size)\n",
    "    # mask has dimensions (batch_size, q_length, k_length)\n",
    "    # Q, K and V are linear layers: emb_size -> emb_size\n",
    "    emb_size = queries.size(-1)\n",
    "    \n",
    "    queries = Q(queries)\n",
    "    keys = K(keys)\n",
    "    values = V(values)\n",
    "    \n",
    "    a = torch.matmul(queries, keys.transpose(-1, -2)) / math.sqrt(emb_size)\n",
    "    \n",
    "    if mask is not None:\n",
    "        a = a.masked_fill(mask == 0, -torch.inf)\n",
    "        \n",
    "    alpha = F.softmax(a, -1)\n",
    "    \n",
    "    return torch.matmul(alpha, values)\n",
    "    \n",
    "\n",
    "def multi_head_attention(queries, keys, values, Q, K, V, proj, n_heads=8, mask=None):\n",
    "    # queries, keys and values have dimensions (batch_size, length, emb_size)\n",
    "    # mask has dimensions (batch_size, q_length, k_length)\n",
    "    # Q, K and V are linear layers: emb_size -> emb_size\n",
    "    \n",
    "    batch_size = queries.size(0)\n",
    "    emb_size = queries.size(-1)\n",
    "    head_emb_size = emb_size // n_heads\n",
    "    \n",
    "    assert emb_size % n_heads == 0\n",
    "    \n",
    "    queries = Q(queries).view(batch_size, -1, n_heads, head_emb_size).transpose(1, 2)\n",
    "    keys = K(keys).view(batch_size, -1, n_heads, head_emb_size).transpose(1, 2)\n",
    "    values = V(values).view(batch_size, -1, n_heads, head_emb_size).transpose(1, 2)\n",
    "    \n",
    "    a = torch.matmul(queries, keys.transpose(-1, -2)) / math.sqrt(head_emb_size)\n",
    "    \n",
    "    if mask is not None:\n",
    "        mask = mask.unsqueeze(1)\n",
    "        a = a.masked_fill(mask == 0, -torch.inf)\n",
    "        \n",
    "    alpha = F.softmax(a, -1)\n",
    "    \n",
    "    z = torch.matmul(alpha, values).transpose(1, 2).contiguous().view(batch_size, -1, emb_size)\n",
    "    \n",
    "    return proj(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44567248",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = torch.randn((2, 10, 32))\n",
    "keys = torch.randn((2, 5, 32))\n",
    "values = torch.randn((2, 5, 32))\n",
    "\n",
    "Q = Linear(32, 32)\n",
    "K = Linear(32, 32)\n",
    "V = Linear(32, 32)\n",
    "proj = Linear(32, 32)\n",
    "\n",
    "mask = torch.ones((2, 10, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db64cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention(queries, keys, values, Q, K, V, mask).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e085838c",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_head_attention(queries, keys, values, Q, K, V, proj, 8, mask).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f888c560",
   "metadata": {},
   "outputs": [],
   "source": [
    "(batch_size, n_queries, n_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b789beae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_masks(x, y, pad_id=0):\n",
    "    # x and y have dimensions (batch_size, length)\n",
    "    enc_mask = (x != 0).unsqueeze(1)\n",
    "    dec_mask = ~torch.triu(torch.ones((1, y.size(-1), y.size(-1))), 1).to(torch.bool)\n",
    "    dec_mask = dec_mask & (y != 0).unsqueeze(1)\n",
    "    \n",
    "    return enc_mask.to(torch.uint8), dec_mask.to(torch.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1056fcfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [[1, 2, 5, 3, 2, 0, 0],\n",
    "     [1, 3, 5, 0, 0, 0, 0]]\n",
    "\n",
    "y = [[1, 2, 5, 0, 0],\n",
    "     [1, 2, 0, 0, 0]]\n",
    "\n",
    "x = torch.tensor(x, dtype=torch.int32)\n",
    "y = torch.tensor(y, dtype=torch.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7708d5ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "make_masks(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14a4978",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttentionBlock(Module):\n",
    "    def __init__(self, emb_size=512, n_heads=8, dropout_p=0.1):\n",
    "        super().__init__()\n",
    "        self.n_heads = n_heads\n",
    "        self.Q = Linear(emb_size, emb_size)\n",
    "        self.K = Linear(emb_size, emb_size)\n",
    "        self.V = Linear(emb_size, emb_size)\n",
    "        self.proj = Linear(emb_size, emb_size)\n",
    "        self.layernorm = LayerNorm(emb_size)\n",
    "        self.dropout = Dropout(0.1)\n",
    "        \n",
    "    def forward(self, queries, keys, values, mask=None):\n",
    "        z = multi_head_attention(queries, keys, values, self.Q, self.K, self.V, self.proj, self.n_heads, mask)\n",
    "        return self.layernorm(queries + self.dropout(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b98e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCNNBlock(Module):\n",
    "    def __init__(self, emb_size=512, hidden_size=2048, dropout_p=0.1):\n",
    "        super().__init__()\n",
    "        self.linear1 = Linear(emb_size, hidden_size)\n",
    "        self.linear2 = Linear(hidden_size, emb_size)\n",
    "        self.layernorm = LayerNorm(emb_size)\n",
    "        self.dropout = Dropout(dropout_p)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        z = self.linear2(F.relu(self.linear1(x)))\n",
    "        return self.layernorm(x + self.dropout(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a21ed0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(Module):\n",
    "    def __init__(self, emb_size=512, n_heads=8, fcnn_hidden_size=2048, dropout_p=0.1):\n",
    "        super().__init__()\n",
    "        self.mha = MultiHeadAttentionBlock(emb_size, n_heads, dropout_p)\n",
    "        self.fcnn = FCNNBlock(emb_size, fcnn_hidden_size, dropout_p)\n",
    "        \n",
    "    def forward(self, x, mask=None):\n",
    "        return self.fcnn(self.mha(x, x, x, mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49893c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn((2, 10, 512))\n",
    "encoder_layer = EncoderLayer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8231cff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_layer(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e911e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embeddings(Module):\n",
    "    def __init__(self, vocab_size, emb_size=512, max_length=4096, dropout_p=0.1):\n",
    "        super().__init__()\n",
    "        self.embeddings = Embedding(vocab_size, emb_size)\n",
    "        self.dropout = Dropout(dropout_p)\n",
    "        \n",
    "        i = torch.arange(max_length).unsqueeze(1)\n",
    "        j = torch.arange(emb_size // 2)\n",
    "        pe = torch.zeros(max_length, emb_size)\n",
    "        pe[:, ::2] = torch.sin(i / torch.pow(10000, 2 * j / emb_size))\n",
    "        pe[:, 1::2] = torch.cos(i / torch.pow(10000, 2 * j / emb_size))\n",
    "        self.register_buffer('pe', pe)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.dropout(self.embeddings(x) + self.pe[:x.size(1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e37f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [[1, 2, 5, 3, 2, 0, 0],\n",
    "     [1, 3, 5, 0, 0, 0, 0]]\n",
    "\n",
    "x = torch.tensor(x, dtype=torch.int32)\n",
    "\n",
    "embeddings = Embeddings(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c021b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c80929",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_size,\n",
    "        max_length=4096,\n",
    "        n_layers=6,\n",
    "        emb_size=512,\n",
    "        n_heads=8,\n",
    "        fcnn_hidden_size=2048,\n",
    "        dropout_p=0.1\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.embeddings = Embeddings(vocab_size, emb_size, max_length, dropout_p)\n",
    "        self.layers = ModuleList(\n",
    "            EncoderLayer(emb_size, n_heads, fcnn_hidden_size, dropout_p) for _ in range(n_layers)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, mask=None):\n",
    "        z = self.embeddings(x)\n",
    "        for layer in self.layers:\n",
    "            z = layer(z, mask)\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fcfb722",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [[1, 2, 5, 3, 2, 0, 0],\n",
    "     [1, 3, 5, 0, 0, 0, 0]]\n",
    "\n",
    "x = torch.tensor(x, dtype=torch.int32)\n",
    "\n",
    "encoder = Encoder(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6997a551",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ec43df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(Module):\n",
    "    def __init__(self, emb_size=512, n_heads=8, fcnn_hidden_size=2048, dropout_p=0.1):\n",
    "        super().__init__()\n",
    "        self.mha_self = MultiHeadAttentionBlock(emb_size, n_heads, dropout_p)\n",
    "        self.mha_enc_dec = MultiHeadAttentionBlock(emb_size, n_heads, dropout_p)\n",
    "        self.fcnn = FCNNBlock(emb_size, fcnn_hidden_size, dropout_p)\n",
    "        \n",
    "    def forward(self, h, x, enc_mask=None, dec_mask=None):\n",
    "        z = self.mha_self(x, x, x, dec_mask)\n",
    "        z = self.mha_enc_dec(z, h, h, enc_mask)\n",
    "        return self.fcnn(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e75384a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [[1, 2, 5, 3, 2, 0, 0],\n",
    "     [1, 3, 5, 0, 0, 0, 0]]\n",
    "\n",
    "y = [[1, 2, 5, 0, 0],\n",
    "     [1, 2, 0, 0, 0]]\n",
    "\n",
    "x = torch.tensor(x, dtype=torch.int32)\n",
    "y = torch.tensor(y, dtype=torch.int32)\n",
    "\n",
    "enc_mask, dec_mask = make_masks(x, y)\n",
    "\n",
    "y = torch.randn((2, 5, 512))\n",
    "\n",
    "encoder = Encoder(6)\n",
    "decoder_layer = DecoderLayer()\n",
    "\n",
    "h = encoder(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1217e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_layer(h, y, enc_mask, dec_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7109406a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_size,\n",
    "        max_length=4096,\n",
    "        n_layers=6,\n",
    "        emb_size=512,\n",
    "        n_heads=8,\n",
    "        fcnn_hidden_size=2048,\n",
    "        dropout_p=0.1\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.embeddings = Embeddings(vocab_size, emb_size, max_length, dropout_p)\n",
    "        self.layers = ModuleList(\n",
    "            DecoderLayer(emb_size, n_heads, fcnn_hidden_size, dropout_p) for _ in range(n_layers)\n",
    "        )\n",
    "        \n",
    "    def forward(self, h, y, enc_mask=None, dec_mask=None):\n",
    "        z = self.embeddings(y)\n",
    "        for layer in self.layers:\n",
    "            z = layer(h, z, enc_mask, dec_mask)\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd425c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [[1, 2, 5, 3, 2, 0, 0],\n",
    "     [1, 3, 5, 0, 0, 0, 0]]\n",
    "\n",
    "y = [[1, 2, 5, 0, 0],\n",
    "     [1, 2, 0, 0, 0]]\n",
    "\n",
    "x = torch.tensor(x, dtype=torch.int32)\n",
    "y = torch.tensor(y, dtype=torch.int32)\n",
    "\n",
    "enc_mask, dec_mask = make_masks(x, y)\n",
    "\n",
    "encoder = Encoder(6)\n",
    "decoder = Decoder(6)\n",
    "\n",
    "h = encoder(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b608ee41",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder(h, y, enc_mask, dec_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e325e90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        enc_vocab_size,\n",
    "        dec_vocab_size,\n",
    "        max_length=4096,\n",
    "        n_layers=6,\n",
    "        emb_size=512,\n",
    "        n_heads=8,\n",
    "        fcnn_hidden_size=2048,\n",
    "        dropout_p=0.1\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(enc_vocab_size, max_length, n_layers, emb_size, n_heads, fcnn_hidden_size, dropout_p)\n",
    "        self.decoder = Decoder(dec_vocab_size, max_length, n_layers, emb_size, n_heads, fcnn_hidden_size, dropout_p)\n",
    "        \n",
    "    def forward(self, x, y, enc_mask=None, dec_mask=None):\n",
    "        h = self.encoder(x, enc_mask)\n",
    "        z = self.decoder(h, y, enc_mask, dec_mask)\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1f9497",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [[1, 2, 5, 3, 2, 0, 0],\n",
    "     [1, 3, 5, 0, 0, 0, 0]]\n",
    "\n",
    "y = [[1, 2, 5, 0, 0],\n",
    "     [1, 2, 0, 0, 0]]\n",
    "\n",
    "x = torch.tensor(x, dtype=torch.int32)\n",
    "y = torch.tensor(y, dtype=torch.int32)\n",
    "\n",
    "enc_mask, dec_mask = make_masks(x, y)\n",
    "\n",
    "transformer = Transformer(6, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff05f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer(x, y, enc_mask, dec_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34283886",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqModel(Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        enc_vocab_size,\n",
    "        dec_vocab_size,\n",
    "        max_length=4096,\n",
    "        n_layers=6,\n",
    "        emb_size=512,\n",
    "        n_heads=8,\n",
    "        fcnn_hidden_size=2048,\n",
    "        dropout_p=0.1\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.transformer = Transformer(enc_vocab_size, dec_vocab_size, max_length, n_layers, emb_size, n_heads, fcnn_hidden_size, dropout_p)\n",
    "        self.logits = Linear(emb_size, dec_vocab_size)\n",
    "        \n",
    "    def forward(self, x, y, enc_mask=None, dec_mask=None):\n",
    "        s = self.transformer(x, y, enc_mask, dec_mask)\n",
    "        return self.logits(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad842ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [[1, 2, 5, 3, 2, 0, 0],\n",
    "     [1, 3, 5, 0, 0, 0, 0]]\n",
    "\n",
    "y = [[1, 2, 5, 0, 0],\n",
    "     [1, 2, 0, 0, 0]]\n",
    "\n",
    "x = torch.tensor(x, dtype=torch.int32)\n",
    "y = torch.tensor(y, dtype=torch.int32)\n",
    "\n",
    "enc_mask, dec_mask = make_masks(x, y)\n",
    "\n",
    "model = Seq2SeqModel(6, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232ea965",
   "metadata": {},
   "outputs": [],
   "source": [
    "model(x, y, enc_mask, dec_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2340bc5",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53bec7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqDataset(Dataset):\n",
    "    def __init__(self, n_samples, vocab_size, min_length=3, max_length=32, seed=None):\n",
    "        self.pad_id = 0\n",
    "        self.bos_id = 1\n",
    "        self.eos_id = 2\n",
    "        if seed is not None:\n",
    "            fix_seed(seed)\n",
    "        self.data = []\n",
    "        for i in range(n_samples):\n",
    "            length = np.random.randint(min_length, max_length + 1)\n",
    "            generated = np.random.randint(3, vocab_size, length).tolist()\n",
    "            x = [self.bos_id] + generated + [self.eos_id] + [self.pad_id] * (max_length - length)\n",
    "            y = [self.bos_id] + generated[::-1] + [self.eos_id] + [self.pad_id] * (max_length - length)\n",
    "            self.data.append((x, y))\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ad3fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate(data):\n",
    "    x, y = zip(*data)\n",
    "    return torch.tensor(x, dtype=torch.int32), torch.tensor(y, dtype=torch.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc445c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 32\n",
    "train_dataset_size = 20000\n",
    "n_epoch = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2621ad6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Seq2SeqDataset(train_dataset_size, vocab_size, seed=42)\n",
    "model = Seq2SeqModel(vocab_size, vocab_size, n_layers=3, emb_size=128, fcnn_hidden_size=256)\n",
    "optimizer = Adam(model.parameters(), lr=1e-3)\n",
    "loss_func = CrossEntropyLoss(reduction='none') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95aa86ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(train_dataset, 8, shuffle=True, collate_fn=collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623713df",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_loss = []\n",
    "for i in range(n_epoch):\n",
    "    losses = []\n",
    "    print(f'Epoch {i + 1}')\n",
    "    for x, y in tqdm(dataloader):\n",
    "        curr_y = y[:, :-1]\n",
    "        next_y = y[:, 1:].clone()\n",
    "        next_y[(curr_y == 0) | (curr_y == 2)] = -100\n",
    "        \n",
    "        enc_mask, dec_mask = make_masks(x, curr_y)\n",
    "        \n",
    "        logits = model(x, curr_y, enc_mask, dec_mask)\n",
    "        token_losses = loss_func(logits.transpose(1, 2), next_y.to(torch.long))\n",
    "        loss = token_losses.sum() / (token_losses > 0).sum()\n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    epoch_loss.append(np.mean(losses))\n",
    "    print(f'Loss: {epoch_loss[-1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae6f69b",
   "metadata": {},
   "source": [
    "# Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108822d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, x, max_steps=50):\n",
    "    x = torch.tensor(x, dtype=torch.int32).unsqueeze(0)\n",
    "    ids = [1]\n",
    "    for i in range(max_steps):\n",
    "        y = torch.tensor(ids, dtype=torch.int32).unsqueeze(0)\n",
    "        enc_mask, dec_mask = make_masks(x, y)\n",
    "        with torch.no_grad():\n",
    "            logits = model(x, y, enc_mask, dec_mask)\n",
    "        next_y = logits[0][-1].argmax().item()\n",
    "        ids.append(next_y)\n",
    "        if ids[-1] == 2:\n",
    "            break\n",
    "    return ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd99dfe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eac4ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "y = generate(model, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d74a6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert y == [1, 20, 19, 18, 17, 16, 15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
