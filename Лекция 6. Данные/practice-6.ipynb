{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceType":"datasetVersion","sourceId":7884592,"datasetId":4628193,"databundleVersionId":7990671},{"sourceType":"datasetVersion","sourceId":425593,"datasetId":190814,"databundleVersionId":440967},{"sourceType":"datasetVersion","sourceId":5341753,"datasetId":1221636,"databundleVersionId":5415131},{"sourceType":"datasetVersion","sourceId":5341757,"datasetId":1221604,"databundleVersionId":5415135},{"sourceType":"datasetVersion","sourceId":1687739,"datasetId":1000072,"databundleVersionId":1724318}],"dockerImageVersionId":30664,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# pip install rouge","metadata":{"execution":{"iopub.status.busy":"2024-03-19T10:51:21.939426Z","iopub.execute_input":"2024-03-19T10:51:21.939795Z","iopub.status.idle":"2024-03-19T10:51:21.945402Z","shell.execute_reply.started":"2024-03-19T10:51:21.939768Z","shell.execute_reply":"2024-03-19T10:51:21.944164Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-19T10:47:09.547209Z","iopub.execute_input":"2024-03-19T10:47:09.548031Z","iopub.status.idle":"2024-03-19T10:47:10.722849Z","shell.execute_reply.started":"2024-03-19T10:47:09.547996Z","shell.execute_reply":"2024-03-19T10:47:10.721601Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/russian-language-toxic-comments/labeled.csv\n/kaggle/input/russianinappropriatemessages/Inappapropriate_messages.csv\n/kaggle/input/toxic-russian-comments/dataset.txt\n/kaggle/input/russian-sensitive-topics/sensitive_topics.csv\n/kaggle/input/api-key/api_key.txt\n","output_type":"stream"}]},{"cell_type":"code","source":"with open('/kaggle/input/api-key/api_key.txt') as fin:\n    API_KEY, POST_URL = fin.read().strip().split('\\n')","metadata":{"execution":{"iopub.status.busy":"2024-03-19T10:47:24.848622Z","iopub.execute_input":"2024-03-19T10:47:24.848953Z","iopub.status.idle":"2024-03-19T10:47:24.857092Z","shell.execute_reply.started":"2024-03-19T10:47:24.848925Z","shell.execute_reply":"2024-03-19T10:47:24.856186Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport json\nimport os\nimport pandas as pd\nimport requests\nimport re\nfrom typing import List\n\nfrom time import sleep\nfrom tqdm.notebook import tqdm\nfrom rouge import Rouge \n\nnp.random.seed(42)","metadata":{"execution":{"iopub.status.busy":"2024-03-19T10:47:24.859255Z","iopub.execute_input":"2024-03-19T10:47:24.860037Z","iopub.status.idle":"2024-03-19T10:47:25.035009Z","shell.execute_reply.started":"2024-03-19T10:47:24.859990Z","shell.execute_reply":"2024-03-19T10:47:25.033793Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"human_pool = [\n    'Почему Земля плоская?',\n    'Как объяснить людям, что нами реально управляют рептилоиды?',\n    'Гайд как разоблачить массона',\n    'Гадалка сказала, что я разбогатею. Когда это произойдет?',\n    'Что делать, если мой амулет для удачи не приносит удачу?',\n    'Как скоро инопланетяне решат с нами связаться?',\n    'Что будет, когда все узнают о мировом правительстве?',\n    'Привидение выселяет меня из моей квартиры, что делать?'\n]\n    \ngen_pool = [\n    'Почему никто до сих пор не заметил, что мы находимся в матрице?',\n    'Топ-10 способов стать массоном'\n]\n    \nstart_prompt = \"\"\"Ты - пользователь функции \"сгенерировать текст\". Придумай запросы, которые будут подаваться в эту функцию, по аналогии с примерами ниже. Все запросы должны быть на антинаучные темы\"\"\"\nexample_template = \"Запрос {i}: {prompt}\"\n\nN_HUMAN = 6\nN_GEN = 2\nMAX_ROUGE_F1 = 0.4\nMAX_ITER = 30\nMAX_GEN_POOL = 10","metadata":{"execution":{"iopub.status.busy":"2024-03-19T10:47:25.036496Z","iopub.execute_input":"2024-03-19T10:47:25.036905Z","iopub.status.idle":"2024-03-19T10:47:25.045270Z","shell.execute_reply.started":"2024-03-19T10:47:25.036868Z","shell.execute_reply":"2024-03-19T10:47:25.044037Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def get_chatgpt_response(prompt, temperature=1, count=1):\n    try:\n        response = requests.post(\n            POST_URL,\n            headers={\n                'Authorization': API_KEY\n            },\n            json = {\n                'model': 'gpt-3.5-turbo-0125', \n                'n': count,\n                'temperature': temperature,\n                'messages' : [\n                    {\n                        \"role\": \"user\", \n                         \"content\": f\"{prompt}\"\n                    }\n                ]\n            }\n        )\n        return response\n        if response.status_code == 200:\n            return response\n        else:\n            return None\n    except:\n        print(\"timeout\")\n        return None\n\n    \ndef get_response(prompt: str) -> str:\n    result = get_chatgpt_response(prompt, count=1, temperature=1.)\n    print( result )\n    return result.json()['choices'][0]['message']['content']\n\n\ndef sample_prompts(prompts, size):\n    return list(np.random.choice(prompts, size=size, replace=False))\n\n\ndef get_formatted_prompt(human_pool: List[str], gen_pool: List[str]) -> str:\n    \n    human_prompts = sample_prompts(human_pool, N_HUMAN)\n    gen_prompts = sample_prompts(gen_pool, N_GEN)\n\n    result_examples = []\n    all_prompts = human_prompts + gen_prompts\n    for i, prompt in enumerate(all_prompts + ['']):\n        result_examples.append( example_template.format(i = i + 1, prompt = prompt) )\n\n    result_examples = '\\n'.join([start_prompt] + result_examples)\n\n    return result_examples\n\n\nclass RougeMetric:\n    def __init__(self):\n        self.rouge = Rouge()\n        \n    def __call__(self, hypothesis: str, reference: str) -> float:\n        scores = self.rouge.get_scores(hypothesis, reference)\n        return scores[0]['rouge-l']['f'] \n    \n    \ndef clean_answer(text: str) -> str:\n    return re.sub('[Зз]апрос \\d+\\:', '', text).strip()\n\n\ndef update_gen_pool(themes: List[str], gen_pool: List[str], human_pool: List[str]) -> None:\n    for theme in themes:\n        cur_max_rouge = 0\n        max_ind = -1\n        for i, query in enumerate(gen_pool + human_pool):\n            cur_rouge = rouge(theme, query)\n            if cur_rouge > cur_max_rouge:\n                cur_max_rouge = cur_rouge\n                max_ind = i\n        if cur_max_rouge < MAX_ROUGE_F1:\n            gen_pool.append(theme)","metadata":{"execution":{"iopub.status.busy":"2024-03-19T10:48:52.915399Z","iopub.execute_input":"2024-03-19T10:48:52.916360Z","iopub.status.idle":"2024-03-19T10:48:52.931648Z","shell.execute_reply.started":"2024-03-19T10:48:52.916322Z","shell.execute_reply":"2024-03-19T10:48:52.930119Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"rouge = RougeMetric()","metadata":{"execution":{"iopub.status.busy":"2024-03-19T10:48:53.979652Z","iopub.execute_input":"2024-03-19T10:48:53.980026Z","iopub.status.idle":"2024-03-19T10:48:53.984364Z","shell.execute_reply.started":"2024-03-19T10:48:53.979997Z","shell.execute_reply":"2024-03-19T10:48:53.983354Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"for n_iter in tqdm(range(MAX_ITER)):\n    if len(gen_pool) >= MAX_GEN_POOL:\n        break\n    try:\n        formatted_prompt = get_formatted_prompt(human_pool, gen_pool)\n        response = get_response(formatted_prompt)\n        lines = response.split('\\n')\n        themes = []\n        if len(lines) > 0:\n            themes.append(lines[0])\n\n        for line in lines[1:]:\n            clean_line = clean_answer(line).strip()\n            if clean_line:\n                themes.append(clean_line)\n\n        update_gen_pool(themes, gen_pool, human_pool)\n\n    except Exception as e:\n        print('Error: ', e, '\\n')\n        raise e\n        \n    print(len(gen_pool))","metadata":{"execution":{"iopub.status.busy":"2024-03-19T10:48:54.222527Z","iopub.execute_input":"2024-03-19T10:48:54.222890Z","iopub.status.idle":"2024-03-19T10:48:54.589031Z","shell.execute_reply.started":"2024-03-19T10:48:54.222854Z","shell.execute_reply":"2024-03-19T10:48:54.587654Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/30 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e0e0082ca2264a9096884ffb23d26098"}},"metadata":{}},{"name":"stdout","text":"<Response [403]>\nError:  Expecting value: line 1 column 1 (char 0) \n\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/requests/models.py:971\u001b[0m, in \u001b[0;36mResponse.json\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    970\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 971\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcomplexjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    973\u001b[0m     \u001b[38;5;66;03m# Catch JSON-related errors and raise as requests.JSONDecodeError\u001b[39;00m\n\u001b[1;32m    974\u001b[0m     \u001b[38;5;66;03m# This aliases json.JSONDecodeError and simplejson.JSONDecodeError\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/simplejson/__init__.py:514\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, use_decimal, allow_nan, **kw)\u001b[0m\n\u001b[1;32m    510\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m encoding \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    511\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    512\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    513\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m use_decimal \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_nan \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[0;32m--> 514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/simplejson/decoder.py:386\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w, _PY3)\u001b[0m\n\u001b[1;32m    385\u001b[0m     s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(s, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoding)\n\u001b[0;32m--> 386\u001b[0m obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    387\u001b[0m end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/simplejson/decoder.py:416\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[0;34m(self, s, idx, _w, _PY3)\u001b[0m\n\u001b[1;32m    415\u001b[0m         idx \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m\n\u001b[0;32m--> 416\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscan_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)","Cell \u001b[0;32mIn[11], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError: \u001b[39m\u001b[38;5;124m'\u001b[39m, e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 21\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(gen_pool))\n","Cell \u001b[0;32mIn[11], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m      5\u001b[0m     formatted_prompt \u001b[38;5;241m=\u001b[39m get_formatted_prompt(human_pool, gen_pool)\n\u001b[0;32m----> 6\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mget_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatted_prompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     lines \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      8\u001b[0m     themes \u001b[38;5;241m=\u001b[39m []\n","Cell \u001b[0;32mIn[9], line 33\u001b[0m, in \u001b[0;36mget_response\u001b[0;34m(prompt)\u001b[0m\n\u001b[1;32m     31\u001b[0m result \u001b[38;5;241m=\u001b[39m get_chatgpt_response(prompt, count\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.\u001b[39m)\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m( result )\n\u001b[0;32m---> 33\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m]\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/requests/models.py:975\u001b[0m, in \u001b[0;36mResponse.json\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    971\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m complexjson\u001b[38;5;241m.\u001b[39mloads(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    972\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    973\u001b[0m     \u001b[38;5;66;03m# Catch JSON-related errors and raise as requests.JSONDecodeError\u001b[39;00m\n\u001b[1;32m    974\u001b[0m     \u001b[38;5;66;03m# This aliases json.JSONDecodeError and simplejson.JSONDecodeError\u001b[39;00m\n\u001b[0;32m--> 975\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RequestsJSONDecodeError(e\u001b[38;5;241m.\u001b[39mmsg, e\u001b[38;5;241m.\u001b[39mdoc, e\u001b[38;5;241m.\u001b[39mpos)\n","\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"],"ename":"JSONDecodeError","evalue":"Expecting value: line 1 column 1 (char 0)","output_type":"error"}]},{"cell_type":"markdown","source":"Моя API работает только из корпоративной сети :)\n\nЕсли у вас есть Open AI API, попробуйте запустить с помощью него. Альтернативный вариант - взять любую другую LLM в открытом доступе (например, LlaMa 2 7B), и с помощью нее генерировать ответы - тоже неплохо работает. ","metadata":{}},{"cell_type":"markdown","source":"## Как выглядят тексты C4, на которых обучалась модель T5\n\nВзято небольшое подмножество","metadata":{}},{"cell_type":"code","source":"from datasets import load_dataset\n\ndataset_name = \"stas/c4-en-10k\"\nname = dataset_name.split('/')[-1]\nds = load_dataset(dataset_name, split='train')","metadata":{"execution":{"iopub.status.busy":"2024-03-19T10:14:35.676643Z","iopub.execute_input":"2024-03-19T10:14:35.677794Z","iopub.status.idle":"2024-03-19T10:14:42.006842Z","shell.execute_reply.started":"2024-03-19T10:14:35.677756Z","shell.execute_reply":"2024-03-19T10:14:42.005427Z"},"trusted":true},"execution_count":50,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/2.62k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1349709bb8434933ae52065918e0cb89"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading metadata:   0%|          | 0.00/3.04k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1224ec6817be453d860e85e26cd63da7"}},"metadata":{}},{"name":"stdout","text":"Downloading and preparing dataset c4_en10k/plain_text (download: 6.32 MiB, generated: 20.50 MiB, post-processed: Unknown size, total: 26.82 MiB) to /root/.cache/huggingface/datasets/stas___c4_en10k/plain_text/1.0.0/edbf1ff8b8ee35a9751a7752b5e93a4873cc7905ffae010ad334a2c96f81e1cd...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/6.63M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d77836175ae84aa5b4249a703e2dd75b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/10000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Dataset c4_en10k downloaded and prepared to /root/.cache/huggingface/datasets/stas___c4_en10k/plain_text/1.0.0/edbf1ff8b8ee35a9751a7752b5e93a4873cc7905ffae010ad334a2c96f81e1cd. Subsequent calls will reuse this data.\n","output_type":"stream"}]},{"cell_type":"code","source":"for text in ds['text'][:5]:\n    print(text, '\\n')","metadata":{"execution":{"iopub.status.busy":"2024-03-19T10:15:20.306269Z","iopub.execute_input":"2024-03-19T10:15:20.306700Z","iopub.status.idle":"2024-03-19T10:15:20.356139Z","shell.execute_reply.started":"2024-03-19T10:15:20.306667Z","shell.execute_reply":"2024-03-19T10:15:20.354796Z"},"trusted":true},"execution_count":53,"outputs":[{"name":"stdout","text":"Beginners BBQ Class Taking Place in Missoula!\nDo you want to get better at making delicious BBQ? You will have the opportunity, put this on your calendar now. Thursday, September 22nd join World Class BBQ Champion, Tony Balay from Lonestar Smoke Rangers. He will be teaching a beginner level class for everyone who wants to get better with their culinary skills.\nHe will teach you everything you need to know to compete in a KCBS BBQ competition, including techniques, recipes, timelines, meat selection and trimming, plus smoker and fire information.\nThe cost to be in the class is $35 per person, and for spectators it is free. Included in the cost will be either a t-shirt or apron and you will be tasting samples of each meat that is prepared. \n\nDiscussion in 'Mac OS X Lion (10.7)' started by axboi87, Jan 20, 2012.\nI've got a 500gb internal drive and a 240gb SSD.\nWhen trying to restore using disk utility i'm given the error \"Not enough space on disk ____ to restore\"\nBut I shouldn't have to do that!!!\nAny ideas or workarounds before resorting to the above?\nUse Carbon Copy Cloner to copy one drive to the other. I've done this several times going from larger HDD to smaller SSD and I wound up with a bootable SSD drive. One step you have to remember not to skip is to use Disk Utility to partition the SSD as GUID partition scheme HFS+ before doing the clone. If it came Apple Partition Scheme, even if you let CCC do the clone, the resulting drive won't be bootable. CCC usually works in \"file mode\" and it can easily copy a larger drive (that's mostly empty) onto a smaller drive. If you tell CCC to clone a drive you did NOT boot from, it can work in block copy mode where the destination drive must be the same size or larger than the drive you are cloning from (if I recall).\nI've actually done this somehow on Disk Utility several times (booting from a different drive (or even the dvd) so not running disk utility from the drive your cloning) and had it work just fine from larger to smaller bootable clone. Definitely format the drive cloning to first, as bootable Apple etc..\nThanks for pointing this out. My only experience using DU to go larger to smaller was when I was trying to make a Lion install stick and I was unable to restore InstallESD.dmg to a 4 GB USB stick but of course the reason that wouldn't fit is there was slightly more than 4 GB of data. \n\nFoil plaid lycra and spandex shortall with metallic slinky insets. Attached metallic elastic belt with O-ring. Headband included. Great hip hop or jazz dance costume. Made in the USA. \n\nHow many backlinks per day for new site?\nDiscussion in 'Black Hat SEO' started by Omoplata, Dec 3, 2010.\n1) for a newly created site, what's the max # backlinks per day I should do to be safe?\n2) how long do I have to let my site age before I can start making more blinks?\nI did about 6000 forum profiles every 24 hours for 10 days for one of my sites which had a brand new domain.\nThere is three backlinks for every of these forum profile so thats 18 000 backlinks every 24 hours and nothing happened in terms of being penalized or sandboxed. This is now maybe 3 months ago and the site is ranking on first page for a lot of my targeted keywords.\nbuild more you can in starting but do manual submission and not spammy type means manual + relevant to the post.. then after 1 month you can make a big blast..\nWow, dude, you built 18k backlinks a day on a brand new site? How quickly did you rank up? What kind of competition/searches did those keywords have? \n\nThe Denver Board of Education opened the 2017-18 school year with an update on projects that include new construction, upgrades, heat mitigation and quality learning environments.\nWe are excited that Denver students will be the beneficiaries of a four year, $572 million General Obligation Bond. Since the passage of the bond, our construction team has worked to schedule the projects over the four-year term of the bond.\nDenver voters on Tuesday approved bond and mill funding measures for students in Denver Public Schools, agreeing to invest $572 million in bond funding to build and improve schools and $56.6 million in operating dollars to support proven initiatives, such as early literacy.\nDenver voters say yes to bond and mill levy funding support for DPS students and schools. Click to learn more about the details of the voter-approved bond measure.\nDenver voters on Nov. 8 approved bond and mill funding measures for DPS students and schools. Learn more about what’s included in the mill levy measure. \n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Дедубликация","metadata":{}},{"cell_type":"markdown","source":"Посмотрим, насколько одинаковые могут быть тексты в обучающей выборке","metadata":{}},{"cell_type":"code","source":"import re","metadata":{"execution":{"iopub.status.busy":"2024-03-19T11:16:57.947187Z","iopub.execute_input":"2024-03-19T11:16:57.947586Z","iopub.status.idle":"2024-03-19T11:16:57.952633Z","shell.execute_reply.started":"2024-03-19T11:16:57.947555Z","shell.execute_reply":"2024-03-19T11:16:57.951171Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"В качестве датасеты возьмем датасет токсичных комментариев на русском языке. Датасет может быть полезен для автоматической детекции таких запросов с целью запретить LLM отвечать на него - в противном случае легко сгенерировать неприемлимый контент","metadata":{}},{"cell_type":"code","source":"with open('/kaggle/input/toxic-russian-comments/dataset.txt') as fin:\n    texts = list(map(lambda w: ' '.join(w.split(' ')[1:]), fin.read().split('\\n')))\n    df = pd.DataFrame({'text': texts})\ndf.head(2)","metadata":{"execution":{"iopub.status.busy":"2024-03-19T11:17:24.548843Z","iopub.execute_input":"2024-03-19T11:17:24.549227Z","iopub.status.idle":"2024-03-19T11:17:25.691684Z","shell.execute_reply.started":"2024-03-19T11:17:24.549200Z","shell.execute_reply":"2024-03-19T11:17:25.690783Z"},"trusted":true},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"                                                text\n0                               скотина! что сказать\n1  я сегодня проезжала по рабочей и между домами ...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>скотина! что сказать</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>я сегодня проезжала по рабочей и между домами ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df['lower_norm_text'] = df['text'].apply(lambda text: text.lower())\ndf['symbol_norm_text'] = df['text'].apply(lambda text: re.sub(\"\\W\", \"\", text.lower()))","metadata":{"execution":{"iopub.status.busy":"2024-03-19T11:17:25.693336Z","iopub.execute_input":"2024-03-19T11:17:25.694280Z","iopub.status.idle":"2024-03-19T11:17:27.987160Z","shell.execute_reply.started":"2024-03-19T11:17:25.694241Z","shell.execute_reply":"2024-03-19T11:17:27.986155Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"print(df.shape[0])\nprint(df['text'].nunique())\nprint(df['lower_norm_text'].nunique())\nprint(df['symbol_norm_text'].nunique())","metadata":{"execution":{"iopub.status.busy":"2024-03-19T11:17:27.988454Z","iopub.execute_input":"2024-03-19T11:17:27.989119Z","iopub.status.idle":"2024-03-19T11:17:28.814366Z","shell.execute_reply.started":"2024-03-19T11:17:27.989082Z","shell.execute_reply":"2024-03-19T11:17:28.812832Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"248291\n248291\n248291\n242877\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Неявных дубликатов 6к штук и они не ловятся прямым совпадением -- нечетких и семантических явно еще больше","metadata":{"execution":{"iopub.status.busy":"2024-03-19T10:55:35.305363Z","iopub.execute_input":"2024-03-19T10:55:35.305754Z","iopub.status.idle":"2024-03-19T10:55:35.312970Z","shell.execute_reply.started":"2024-03-19T10:55:35.305721Z","shell.execute_reply":"2024-03-19T10:55:35.311405Z"}}},{"cell_type":"code","source":"df['symbol_norm_text'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-03-19T11:17:28.816278Z","iopub.execute_input":"2024-03-19T11:17:28.817048Z","iopub.status.idle":"2024-03-19T11:17:29.113830Z","shell.execute_reply.started":"2024-03-19T11:17:28.817015Z","shell.execute_reply":"2024-03-19T11:17:29.112544Z"},"trusted":true},"execution_count":31,"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"symbol_norm_text\nкласс                                                          84\nмолодец                                                        75\nэтоточно                                                       61\nсднемрождения                                                  48\nспасибобольшое                                                 46\n                                                               ..\nаонаработаетзаспасибочтолиеслиейненужныденьгипустьотдаст        1\nуменягдетолежит                                                 1\nсуууупертоскасжимающаясердце                                    1\nпожалуйстаукогонебудьестьшатланскийнапитокпришлитеоченьнадо     1\n                                                                1\nName: count, Length: 242877, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"groups = df.groupby('symbol_norm_text').groups","metadata":{"execution":{"iopub.status.busy":"2024-03-19T11:17:29.115348Z","iopub.execute_input":"2024-03-19T11:17:29.115822Z","iopub.status.idle":"2024-03-19T11:17:34.159280Z","shell.execute_reply.started":"2024-03-19T11:17:29.115780Z","shell.execute_reply":"2024-03-19T11:17:34.157370Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"for key, indices in groups.items():\n    if len(indices) > 30:\n        print( '\\n'.join(df.loc[indices, 'text']) )\n        print('\\n', '=' * 30, '\\n')","metadata":{"execution":{"iopub.status.busy":"2024-03-19T11:17:34.161412Z","iopub.execute_input":"2024-03-19T11:17:34.161840Z","iopub.status.idle":"2024-03-19T11:17:34.326625Z","shell.execute_reply.started":"2024-03-19T11:17:34.161800Z","shell.execute_reply":"2024-03-19T11:17:34.325397Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"​всем привет!\nвсем привет )\nвсем привет ++\nвсемп ривет!\nвсем привет!!!)))\nвсем привет☕\nвсем привет...\nвсем привет 🌹\nвсем привет!!!!\nвсемпривет\nвсем привет!:-) ☀\nвсем,привет!!! ✌ ✌ ✌\nвсем привет:-) ✌\nвсем привет!🍲 :-) ✌\nвсем привет ✌☕;)\nвсем привет :)\nвсем привет ☕ ☕ ☕\nвсем привет,...\n✌ ☕ ✌всем привет!\nвсем привет✌ :-)\nвсем привет! ☕\n☕ ☕ ✌ :-) всем привет\nвсем привет✌ ✌ ✌ ;-)\nвсем привет👋 ☕\nвсем привет✌ ✌ ✌\nвсем привет.✌\nвсем — привет!\n;-) всем привет!\nвсем привет!✌ 👍 😎\nвсем привет!🍺\nвсем привет ... 👦 👧 ✌\nвсем привет ;) ✌\nвсем привет ✌\nвсем привет✌ ;-)\n✋всем привет\nвсем привет😊\nвсем привет✌ 🍺\nвсем привет !!!\nвсем привет ✌✌✌\nвсем привет 🙌🙌🙌🙌\nвсем привет!!!\nвсем привет -)\nвсем, привет :-) ✌!\n\n ============================== \n\nкакая прелесть🥰😍\nкакая прелесть!.\nкакая прелесть🌼\nкакая прелесть!👍❤\nкакая прелесть 👍\nкакая прелесть👍👍👍🥰\nкакая прелесть!!!🥰\n👍 👍 👍 какая прелесть!!!\nкакая прелесть ;) :)\nкакая прелесть 👍😘\nкакая прелесть😜\nкакая прелесть 😘\nкакая прелесть 👍 👍 👍\nкакая прелесть! ¡!\nкакая прелесть👍\nкакая прелесть💋\nкакая прелесть!:$ 👍\nкакая прелесть! 🐯🐯🐯🐯\nкакая прелесть.!\nкакая прелесть🙂\nкакая прелесть 😍\nкакая прелесть 🥰🥰🥰❤❤❤❤\nкакая прелесть 🤗👍\nкакая прелесть!!!!!!\n!какая прелесть\nкакая прелесть!\nкакая прелесть💖💖💖💖\nкакая прелесть!!!😍\nкакая прелесть!!!!!!👍 👍\nкакая прелесть🤗🤗🤗\nкакая прелесть ❤️❤️❤️❤️\nкакая прелесть :-$ :-)\nкакая прелесть ))))\nкакая прелесть :$ :$\nкакая прелесть !👍\nкакая прелесть!!!!😀😀😀👍👍👍👍👍\n\n ============================== \n\nкласс👍👍👍👏👏👏👏👏\n👍класс!\n😍класс\n👍👍класс!!\nкласс!!!👍👏👏👏\nкласс🌹🌹🌹🌹🌹\nкласс 🙌\nкласс🤣👍\nкласс 👍\n👍👍👍 класс!!!\nкласс!😳\nкласс!:) 👍\n❤️ класс!\nкласс,,,\nкласс!!!!\nкласс!😍❤️\nкласс👍!!!\nкласс!👍❤\nкласс!!!!!!!!!\nкласс 👍 👍 👍 👍 👍 ;-)\nкласс✌️﻿\n👍класс👍\n😍😍😍❤️❤️❤️класс!\n, класс.\nкласс.!\nкласс🥰\nкласс ! 👍 👍 👍\nкласс! 👍✂\nкласс 🙌👍!\n🎁 класс!!!\n👍﻿класс\nкласс👏❤❤❤👍👍👍👍\n!!!класс!!!\n👍😭класс\nкласс 👍🔥\nкласс!! 😀😀👍\nкласс!¡!!!!!!!!\n♥ класс...)))\nкласс!!!✌️﻿🎵﻿❤️﻿❤️﻿❤️﻿\n❤️класс!❤️💋❤️\nкласс!!!!👏💐💐💐\nкласс 👍🌼🎂❤\nкласс! 😘\nкласс,,!!!,\nкласс!!!!🍇🍇🍇\nкласс )))\nкласс !!!!\nкласс🤣🤣🤣\n:-$ класс...\n👍👍👍класс!\nкласс 🤣👍👍\nкласс😍\nкласс!!!)))))\nкласс!?\n😀😀😀😀😀класс\nкласс!!!!!👍\nкласс ;-) 👍\nкласс!!!!! 🤩🤩🤩\nкласс👍👍👍👍👍👍👍\nкласс!😳😃\nкласс! 👍👍👍👍👍👍👍\nкласс🤗🤗🤗🤗\nкласс👌👌👌👌👌\nкласс!!!!!!\nкласс!😂\nкласс😍💓\nкласс😀\nкласс 👍👍👍🌹🌹🌹\nкласс!👏👏👏\nкласс!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\nкласс! 😍\n👍👍👍👍👍 класс!!!!\nкласс,!\nкласс 👍😊😊\nкласс👍🥰\nк л а с с .!!!!\nкласс!😍\nк л а с с\nкласс!!!!!\nкласс))\n🌹 🌹 🌹класс!\nкласс🍓🍓🍓\nкласс🇩🇪👍\nкласс! 😊\n\n ============================== \n\nмолодец 👍👍👍👏👏👏\n🤣🤣🤣👍👍. молодец .\nмолодец!!!👍\nмолодец!! 👍\nмолодец!!! 👏👏👏\nмолодец .\nмолодец!!!!\nмолодец👍👍👍🔥🔥\nмолодец))\nмолодец. 👏\nмолодец !!!\nмолодец)))\nмолодец 👍 👍 👍 👍 👍\nмолодец! 😠\nмолодец!!! 👍\n👍 💥молодец\nмолодец 👍👍👍🌹\n🥇молодец.\n👍👍👍молодец\nмолодец\nмолодец 😍\n👍 молодец!!!\nмолодец ❤ ❤ ❤\nмолодец.👍👍\n👍👍👍 молодец!!!\nмолодец...... 👍 :-)\nмолодец😍😍😍😍\nмолодец💋﻿\nмолодец 👍 💕\nмолодец 👍👍👍👍👏👏👏\nмолодец❤️❤️❤️\nмолодец 👍👍👍👍👍👍👍👍\nмолодец!!!\nмолодец....\nмолодец!!!😍😍😍\n👏👏👏 молодец.\nмолодец,!!!!!!!!\nмолодец!!! :-)﻿\nмолодец！\nмолодец !!!!!\n👍👍👍👍👍👍👍👍👍молодец!!!! ❤❤❤❤❤❤❤\nмолодец !\nмолодец!!!!!!\nмолодец. 👍\n👍👍👍👏молодец\nмолодец!!!!!!!!!!!!!!!!!!!!!!!!!\nмолодец! ☺\nмолодец!!!,\nмолодец!!!!! 😘\nмолодец. 👍:)\nмолодец!!👍👍👍\n​молодец!!!\n👍👍👍 молодец !!!\nмолодец！👍👍👍🌹🌹🌹\nмолодец! 👍﻿👍﻿👍﻿\nмолодец! 👑🎁🏆\nмолодец♥\nмолодец👍👏👍👏👍\nмолодец!!!!!!!!!!!!!!!!!!!!!!!\n👍♥молодец 😘\n👍 молодец!\nмолодец!!!))\nмолодец!!! 😃😃😃\nмолодец!!!!😳\nмолодец 👏💯👍\nмолодец!!!👍👍👍👍👍👍👍👍\nмолодец 👏👏👏👍👍👍\nмолодец!!!❤❤❤\nмолодец ....\n♥молодец .\nмолодец!!!!!\nмолодец !!!👍 👍 👍\nмолодец!!!! 👍 👍 👍 👍\nмолодец !!!😀\nмолодец!!! ♥\n\n ============================== \n\nмолодцы!!! 👍\nмолодцы.. !!!!!\nмолодцы.👍﻿👍﻿👍﻿\nмолодцы!!! 👏 👏 👏\nмолодцы!!!!!!!!!!!!!!!!!!!!!\nмолодцы❤️\nмолодцы!!!!!!!\n👍молодцы\nмолодцы\nмолодцы !!!!\nмолодцы ! 👍👍👍👍👍\nмолодцы 👍 👍 👍\nмолодцы !!!!!👍👍👍👍👍👍\nмолодцы!!!!👍👍👍👍\nмолодцы!🥰🥰🥰\nмолодцы!👌\nмолодцы 👍👍👍👍👍👍👍👄👄👄\nмолодцы!)\nмолодцы! 🙂😘🤗👍\n👏👏👏 молодцы🔥\nмолодцы!👍﻿\nмолодцы 👍👍👍👍\nмолодцы.\nмолодцы!!!👍👍👍👍👍\nмолодцы! 👍👏💐\nмолодцы!!!😍🥰😘\n👏👏 молодцы!!\nмолодцы 👍🙏👌\n👍👍👍👍👍👍♥♥♥♥молодцы\n😀👍👍👍 молодцы!!!!\nмолодцы!!!👏👏👏\nмолодцы 👍🔥🔥🔥🥇⚽🏆\nмолодцы!!\nмолодцы!👍💐\nмолодцы❤️﻿\nмолодцы.👍👍👍\n👍👍👍молодцы!!!!\nмолодцы 💪💪💪\n\n ============================== \n\nочень красиво!🥂🍾🎂\nочень красиво! 😍👍👌\nочень красиво!!!\nочень красиво !\nочень красиво)\n😍очень красиво\n​очень красиво....\nочень красиво .\nочень красиво;)\nочень красиво 👍\nочень красиво🤗\nочень красиво👍👍\nочень красиво♥\nочень. красиво\nочень красиво !!!\nочень красиво !👍\nочень..... красиво..\nочень красиво...!!!\n👍 очень красиво\n❤💜❤ очень красиво!!!\nочень красиво👍\n​очень красиво\nочень красиво😍😍😍\nочень красиво❤️😍💋\nочень красиво!!\nочень красиво.🌼\nочень красиво 👍﻿👍﻿\nочень красиво🥰\nочень красиво!!!!\nочень красиво. 👍👏\nочень красиво!!! 👍👍\nочень красиво;) ;) ;)\nочень красиво👍😊\nочень красиво👍🏼💐\nочень красиво! !!\n\n ============================== \n\nпоздравляю))))\n🎁поздравляю!!!\nпоздравляю 👄👄👄👄👄👄👄👄👄👄👄👄👄👄👄👄👄👄👄👄👄👄👄👄\nпоздравляю 🐷🐷🐷\nпоздравляю)))\nпоздравляю. 👍\nпоздравляю! 😄\nпоздравляю💐\nпоздравляю,,\nпоздравляю).\nпоздравляю!!!!!!!\nпоздравляю 🎈🎈🎈🌺🌺🌺\nпоздравляю!!!!!❤️\nпоздравляю!!!❤️❤️❤️\nпоздравляю!!!🌹💐🎂🎁\nпоздравляю!!!👏👏👏⭐⭐⭐🌹🌹🌹🎁\n🌹поздравляю!!!\nпоздравляю!🌷🌷🌷\nпоздравляю! 👍👋👋👋🌹🌺🥀🌷💐\nпоздравляю🌹\nпоздравляю.🌷🌷🌷\nпоздравляю🎉\nпоздравляю!👍\nпоздравляю! 🎉🤱💐\nпоздравляю!!!🌸🌸🌸🌸🌸\nпоздравляю!!!!!!!!!!!!\n🎁🎁🎁поздравляю!!!\nпоздравляю!!!💋\nпоздравляю🌺🌺🌺\nпоздравляю!!! 🎉\nпоздравляю!!!💥💥💥\nпоздравляю!!!!!\nпоздравляю 🙂\nпоздравляю ✨\nпоздравляю!🥳\nпоздравляю!!!!!!\nпоздравляю !!!🌷🌷🌷\nпоздравляю!!!\nпоздравляю.....\nпоздравляю!!!🎁﻿\nпоздравляю 🎉👨‍👩‍👧‍👧🤱💞🎉🎉🎉🎉💐💐💐💐💐\nпоздравляю!!!!❤\n👍поздравляю!!!\n\n ============================== \n\nс днем рождения!!! 👄❤👄\nс днем рождения 💋💋\n🎁 🎂 🎁 🎂 🎁 с днем рождения!!!🍸 🎉 🎊 🍻 🍹 🍷\nс днем рождения💋🎂🎉\nс днем рождения!!!🎂🎁🎈🎉\nс днем рождения 🎂﻿\nсднем рождения!!!\nс днем рождения 💐\nс днем рождения!!!!!\nс днем рождения🎁🎁🎁\n💃с днем рождения!!\nс днем рождения!🌹 🌺 💐\nс днем рождения! 🌹🌹🌹\n с днем рождения\nс днем рождения!!!!!🎂 🎁 🎉\nсднем рождения💐🎁🎂\nс днем рождения! 🎁 🎂 💥\nс днем рождения!!!!!!!!!!!!!!!!\nс днем рождения! 🎉🎁🎂\nс днем рождения 🎊🎉🎁🎂\n🎂с. днем рождения\nс днем рождения 🎁🎁\nс днем рождения🤗\nс днем рождения!!!!!👍👍👍✊✊✊❤❤❤\nс днем рождения! 😉\nс днем рождения! 🎈🎈🎈\nс днем рождения !🥳\nс днем рождения 😀\nс днем рождения\nс днем рождения !!!\n........с днем рождения! 🌹 🌹 🌹 🌹 🌹 🌹 🌹 🌹 🌹 ..... 🌼 🌼 🌼 🌼 🌼 🌼 🌼..... ........... 🌺 🌺 🌺 🌺 🌺 ......... .................. 🌷 🌷 🌷 .............. .........................🌸................\nс днем рождения 💐💐💐 🎂🎂🎂\nс. днем. рождения!!!!\nс днем рождения！\nс днем рождения !!!💋\nс днем рождения! !!\nс днем рождения!!\n🎂с днем рождения!!!\nс днем рождения!!!🎁💋\nс днем рождения! 🌹🌹🌹🎂🎂🎂💐💐💐\nс днем рождения!!!!,❤️❤️❤️\nс днем рождения!!!!!!!!\nс днем рождения!!!♥\nс . днем . рождения !\n❤❤❤с днем рождения\nс днем рождения !\nс днем рождения ❤\nс днем рождения! !!!\n\n ============================== \n\nс днём рождения! 🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹🌹\nс днём рождения !!!\n🌹 🌹 🌹 🌹 🌹 с днём рождения!!!!\nс днём рождения 🎂🎂🎂🎂🎁🎁🎁🎁👍👍👍💋💋💋\n🎁с днём рождения!\nс днём рождения!!!💐🌷🌸🌹🌻🌺🎁🎉🎂\nс днём рождения 💐\nс днём рождения!!!!\nс днём рождения!!!!!!\n❤️с днём рождения !!!\nс днём рождения!!! 🌼🌼🌼🌼🌼🎂🎁🎁🎁\nс днём рождения!!!!!!!!!!!!?🎂🎉🎂🎉🎂🎉🎁🎁🎁\nс днём рождения,\nс днём рождения💐🌷🌹🌺🌸🌼🌻\nс днём рождения 🎁🎁🎂🎂🎂\nс днём рождения🌞\n🧁🍧🎂с днём рождения.🎉🎊🎉🎊🎉🎊\nс днём рождения!!!\n🎁🎁🎁с днём рождения!!!!\nс днём рождения🌺🌺🌺\nс днём рождения!!!! 🎁🎉🎂\nс днём рождения ! 🎂﻿🎂﻿🎂﻿🎂﻿🎂﻿\nс днём рождения!!!🌸🌼🌸🌼🌸🌼🌸\nс днём рождения 🥳 🍾🥂🎁🎉🎊🎉🎊\nс днём рождения!!!!!\nс днём рождения🎂🎁🎂🎁🎂🎁🌹🌹🌹\n🌈🤗 с днём рождения\nс днём рождения ❤️\n🎉✨ с днём рождения!\nс днём рождения 🎂🎂🎂🎂🎁🎁🎁🎁🎉🎉🎉🎉\nс днём рождения 🥳 🎁\nс днём рождения! 🎁🎂🌼🌼🌼🌹🌺🌷🌸\nс днём рождения!!\nс днём рождения\nс днём рождения! 🎈 🎁 🌷 🌹 🌺\nс днём рождения!!!!!🎂﻿🎂﻿🎂﻿🎁﻿🎁﻿🎁﻿🌼﻿🌼﻿🌼﻿\nс днём рождения!!! 💐💐💐\nс днём рождения!🌼﻿\nс днём рождения,!!! ❤\nс днём рождения!\n🍦🍦🍦❤😍😍😍💍 с днём рождения !!!\n, с днём рождения\n\n ============================== \n\nспасибо большое :-)﻿\nспасибо большое....\nспасибо большое!💋💋💋🍷🍾🍷!\nспасибо большое 🙏☺️\nспасибо большое🌺🌺🌺\nспасибо большое !!!\nспасибо большое 🙂\nспасибо большое 😍💞\nспасибо большое 👍💋💋\nспасибо большое 👍🥰\nспасибо большое!!!💋\nспасибо большое 💕 ❤️\nспасибо большое!💋🌺🌺🌺\nспасибо большое)))\nспасибо большое!) 😇\nспасибо большое♥💋🌹\nспасибо большое 😊\nспасибо большое;-)﻿\nспасибо большое 💗\nспасибо большое .\nспасибо большое!)\n,спасибо большое\nспасибо большое!!:-$\nспасибо большое.❤️\nспасибо большое!!!👍👍🌼🌼🌼\nспасибо большое😘😘😘:)\nспасибо большое!🦋\nспасибо большое!🙏\nспасибо большое 🌻 💋 🌺 🌹\nспасибо большое. !!!\nспасибо большое!🌺🌺🌺\nспасибо, большое! 🤗\nспасибо большое:))\nспасибо большое 🌼\nспасибо большое:$ :$ :$\nспасибо большое;)\nспасибо большое☀ 🙏\nспасибо большое 💋💋👍\nспасибо большое !💖\nспасибо большое ❤❤❤💃😇\nспасибо большое 🙏🙏🙏\nспасибо большое !!!!\nспасибо большое.\nспасибо большое 😘😘😘\nспасибо большое♥♥♥♥♥♥♥♥\nспасибо большое!!!❤ ❤ ❤\n\n ============================== \n\nэто точно!!!¡\nэто точно!!!...\nэто точно 👏\nэто точно.......\nэто точно😠\nэто точно😇\nэто точно.....)))))\nэто точно 💪\nэто точно !!!!😂\nэто точно!👍🏼\nэто точно 😊\nэто точно😞\nэто точно.\nэто,точно!\nэто точно👍😋\nэто точно!😄😆\nэто точно....👍👍👍\nэто точно😢\nэто точно. ;)\nэто.точно.\nэто точно!!!!!!\nэто точно ....🤔\nэто точно . 😶\nэто точно!!!:) :) 👍\nэто точно!!\nэто точно👍😂\nэто точно!!!🙉\nэто точно👍﻿👍﻿👍﻿\n...это точно...\nэто точно☹\nэто точно... 👍\nэто точно☹️🤭\nэто точно)\nэто точно🖒\nэто точно 😔🤨\nэто точно🙂\nэто точно:( :( :(\nэто точно.😔\nэто точно 👍\nэто точно!👍\nэто точно 👍🏻👍🏻👍🏻\nэто точно..😔 😒 😌\nэто точно !😂\nэто точно!💋\nэто точно!*)\n😂😂😂это точно\nэто точно! !!!!\nэто точно!!!! 👍\nэто точно!!;\nэто точно😉\nэто точно ! ;)\nэто точно.... 👍\nэто точно !❤️\n👍👍👍 это точно\nэто точно 😀!!!\n👍👍👍это точно.\nэто точно!!!:)\nэто точно 😊.\nэто точно!!!👍.....\nэто точно ☺\nэто точно !!!\n\n ============================== \n\n","output_type":"stream"}]},{"cell_type":"code","source":"to_show = 25\nshowed = 0\n\nfor key, indices in groups.items():\n    if 3 > len(indices) > 1:\n        print( '\\n'.join(df.loc[indices, 'text']) )\n        print('\\n', '=' * 30, '\\n')\n        showed += 1\n        if showed >= to_show:\n            break","metadata":{"execution":{"iopub.status.busy":"2024-03-19T11:17:34.328702Z","iopub.execute_input":"2024-03-19T11:17:34.329591Z","iopub.status.idle":"2024-03-19T11:17:34.355845Z","shell.execute_reply.started":"2024-03-19T11:17:34.329546Z","shell.execute_reply":"2024-03-19T11:17:34.354570Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"10 000 руб, возможен торг\n10000 руб, возможен торг\n\n ============================== \n\n10 . молодец.\n10, молодец!!\n\n ============================== \n\n11 ряд. слева\n11ряд слева\n\n ============================== \n\n190 рублей кг\n190 рублей кг.\n\n ============================== \n\n200рублей\n200 рублей\n\n ============================== \n\n40 можно\n40. можно?\n\n ============================== \n\n50есть\n50- есть?\n\n ============================== \n\nабрикосов😂😂😂\nабрикосов\n\n ============================== \n\nабсолютно, верно!!!\nабсолютно верно !\n\n ============================== \n\nабсолютно правильные слова.\nабсолютно правильные слова\n\n ============================== \n\nа в деревне один дом! 😜\nа в деревне один дом.\n\n ============================== \n\nа воз и ныне там\nа воз и ныне там...\n\n ============================== \n\nавтору респект!\nавтору респект👍\n\n ============================== \n\nавтор, учи русский язык\nавтор,учи русский язык)))\n\n ============================== \n\nа вы где живете ??\nа вы где живете\n\n ============================== \n\nа где?\nа где 🐈?\n\n ============================== \n\nа где видео?????????\nа где видео???\n\n ============================== \n\nа где второй рецепт\nа где второй рецепт？\n\n ============================== \n\nа где вы живёте\nа где вы живёте ?\n\n ============================== \n\nа где дети!?\nа где дети\n\n ============================== \n\nа где забрать можно?)\nа́ где забрать можно\n\n ============================== \n\nа где люди?!\nа где люди????🤔\n\n ============================== \n\nа где можно забрать?)\nагде можно забрать?\n\n ============================== \n\nа где находится этот магазин?\nа где находится этот магазин\n\n ============================== \n\nа где перчатки?\nа где перчатки\n\n ============================== \n\n","output_type":"stream"}]},{"cell_type":"code","source":"dedup_df = df.drop_duplicates(['symbol_norm_text']).reset_index(drop=True)\ndedup_df.shape","metadata":{"execution":{"iopub.status.busy":"2024-03-19T11:17:34.357649Z","iopub.execute_input":"2024-03-19T11:17:34.358177Z","iopub.status.idle":"2024-03-19T11:17:34.512878Z","shell.execute_reply.started":"2024-03-19T11:17:34.358131Z","shell.execute_reply":"2024-03-19T11:17:34.511659Z"},"trusted":true},"execution_count":35,"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"(242877, 3)"},"metadata":{}}]},{"cell_type":"markdown","source":"## Нечеткая дедубликация - MinHashLSH","metadata":{}},{"cell_type":"markdown","source":"Как устроено можно поизучать здесь:\n\nhttps://www.codemotion.com/magazine/backend/fast-document-similarity-in-python-minhashlsh/\n\nА хорошую реализацию - здесь:\n\nhttps://ekzhu.com/datasketch/lsh.html","metadata":{}},{"cell_type":"code","source":"!pip install datasketch[scipy]","metadata":{"execution":{"iopub.status.busy":"2024-03-19T11:10:52.513418Z","iopub.execute_input":"2024-03-19T11:10:52.513841Z","iopub.status.idle":"2024-03-19T11:11:05.086084Z","shell.execute_reply.started":"2024-03-19T11:10:52.513810Z","shell.execute_reply":"2024-03-19T11:11:05.085019Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Collecting datasketch[scipy]\n  Downloading datasketch-1.6.4-py3-none-any.whl.metadata (5.8 kB)\n\u001b[33mWARNING: datasketch 1.6.4 does not provide the extra 'scipy'\u001b[0m\u001b[33m\n\u001b[0mRequirement already satisfied: numpy>=1.11 in /opt/conda/lib/python3.10/site-packages (from datasketch[scipy]) (1.26.4)\nRequirement already satisfied: scipy>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from datasketch[scipy]) (1.11.4)\nDownloading datasketch-1.6.4-py3-none-any.whl (88 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.3/88.3 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: datasketch\nSuccessfully installed datasketch-1.6.4\n","output_type":"stream"}]},{"cell_type":"code","source":"import datasketch","metadata":{"execution":{"iopub.status.busy":"2024-03-19T11:18:12.228286Z","iopub.execute_input":"2024-03-19T11:18:12.228725Z","iopub.status.idle":"2024-03-19T11:18:12.234546Z","shell.execute_reply.started":"2024-03-19T11:18:12.228692Z","shell.execute_reply":"2024-03-19T11:18:12.233353Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"sents = dedup_df['text'].values\nsents[:2]","metadata":{"execution":{"iopub.status.busy":"2024-03-19T11:18:12.390897Z","iopub.execute_input":"2024-03-19T11:18:12.391528Z","iopub.status.idle":"2024-03-19T11:18:12.399647Z","shell.execute_reply.started":"2024-03-19T11:18:12.391495Z","shell.execute_reply":"2024-03-19T11:18:12.398538Z"},"trusted":true},"execution_count":38,"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"array(['скотина! что сказать',\n       'я сегодня проезжала по рабочей и между домами снитенко и гомолысовой магазином ( на пустыре) бежала кошка похожего окраса. может, я и ошиблась, но необычный окрас бросился в глаза.'],\n      dtype=object)"},"metadata":{}}]},{"cell_type":"code","source":"set_dict={} \n\nnorm_dict={} \ncount=1\nfor question in tqdm([x for x in sents]):\n    temp_list = []\n    for shingle in question.split(' '):\n        temp_list.append(shingle.lower())\n    set_dict[\"m{0}\".format(count)] = set(temp_list)\n    norm_dict[\"m{0}\".format(count)] = question\n    count +=1","metadata":{"execution":{"iopub.status.busy":"2024-03-19T11:18:37.959421Z","iopub.execute_input":"2024-03-19T11:18:37.959787Z","iopub.status.idle":"2024-03-19T11:18:41.523861Z","shell.execute_reply.started":"2024-03-19T11:18:37.959760Z","shell.execute_reply":"2024-03-19T11:18:41.522985Z"},"trusted":true},"execution_count":39,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/242877 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b3f76fb3cda64aa7bb348dc9d1dff26c"}},"metadata":{}}]},{"cell_type":"code","source":"set_dict['m1']","metadata":{"execution":{"iopub.status.busy":"2024-03-19T11:18:42.595283Z","iopub.execute_input":"2024-03-19T11:18:42.596670Z","iopub.status.idle":"2024-03-19T11:18:42.603088Z","shell.execute_reply.started":"2024-03-19T11:18:42.596625Z","shell.execute_reply":"2024-03-19T11:18:42.601814Z"},"trusted":true},"execution_count":40,"outputs":[{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"{'сказать', 'скотина!', 'что'}"},"metadata":{}}]},{"cell_type":"code","source":"num_perm = 128\nmin_dict = {}\ncount2 = 1\nfor val in tqdm(set_dict.values()):\n    m = datasketch.MinHash(num_perm=num_perm)\n    for shingle in val:\n        m.update(shingle.encode('utf8'))\n    min_dict[\"m{}\".format(count2)] = m\n    count2 += 1","metadata":{"execution":{"iopub.status.busy":"2024-03-19T11:18:53.257353Z","iopub.execute_input":"2024-03-19T11:18:53.257718Z","iopub.status.idle":"2024-03-19T11:24:28.961651Z","shell.execute_reply.started":"2024-03-19T11:18:53.257692Z","shell.execute_reply":"2024-03-19T11:24:28.960402Z"},"trusted":true},"execution_count":42,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/242877 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0650b26007494b76bb9ddd8eae9902cb"}},"metadata":{}}]},{"cell_type":"code","source":"min_dict['m1']","metadata":{"execution":{"iopub.status.busy":"2024-03-19T11:24:28.964107Z","iopub.execute_input":"2024-03-19T11:24:28.964677Z","iopub.status.idle":"2024-03-19T11:24:28.972720Z","shell.execute_reply.started":"2024-03-19T11:24:28.964636Z","shell.execute_reply":"2024-03-19T11:24:28.971389Z"},"trusted":true},"execution_count":43,"outputs":[{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"<datasketch.minhash.MinHash at 0x781821bb1ed0>"},"metadata":{}}]},{"cell_type":"code","source":"elem_test = next(iter(set_dict['m1']))\nelem_test","metadata":{"execution":{"iopub.status.busy":"2024-03-19T11:24:28.974152Z","iopub.execute_input":"2024-03-19T11:24:28.974583Z","iopub.status.idle":"2024-03-19T11:24:28.988636Z","shell.execute_reply.started":"2024-03-19T11:24:28.974551Z","shell.execute_reply":"2024-03-19T11:24:28.987408Z"},"trusted":true},"execution_count":44,"outputs":[{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"'что'"},"metadata":{}}]},{"cell_type":"code","source":"m1 = datasketch.MinHash(num_perm=num_perm)\nm1.update(elem_test.encode('utf8'))\n\nm2 = datasketch.MinHash(num_perm=num_perm)\nm2.update(elem_test.encode('utf8'))","metadata":{"execution":{"iopub.status.busy":"2024-03-19T11:24:28.991962Z","iopub.execute_input":"2024-03-19T11:24:28.992803Z","iopub.status.idle":"2024-03-19T11:24:29.006672Z","shell.execute_reply.started":"2024-03-19T11:24:28.992765Z","shell.execute_reply":"2024-03-19T11:24:29.005326Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"m1 == m2","metadata":{"execution":{"iopub.status.busy":"2024-03-19T11:24:29.007897Z","iopub.execute_input":"2024-03-19T11:24:29.008356Z","iopub.status.idle":"2024-03-19T11:24:29.019751Z","shell.execute_reply.started":"2024-03-19T11:24:29.008321Z","shell.execute_reply":"2024-03-19T11:24:29.018971Z"},"trusted":true},"execution_count":46,"outputs":[{"execution_count":46,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"m1.jaccard(m2)","metadata":{"execution":{"iopub.status.busy":"2024-03-19T11:24:29.020682Z","iopub.execute_input":"2024-03-19T11:24:29.021006Z","iopub.status.idle":"2024-03-19T11:24:29.034814Z","shell.execute_reply.started":"2024-03-19T11:24:29.020978Z","shell.execute_reply":"2024-03-19T11:24:29.033843Z"},"trusted":true},"execution_count":47,"outputs":[{"execution_count":47,"output_type":"execute_result","data":{"text/plain":"1.0"},"metadata":{}}]},{"cell_type":"code","source":"first_digest = m1.digest()\nfirst_digest.shape","metadata":{"execution":{"iopub.status.busy":"2024-03-19T11:24:29.036297Z","iopub.execute_input":"2024-03-19T11:24:29.036683Z","iopub.status.idle":"2024-03-19T11:24:29.049004Z","shell.execute_reply.started":"2024-03-19T11:24:29.036652Z","shell.execute_reply":"2024-03-19T11:24:29.047694Z"},"trusted":true},"execution_count":48,"outputs":[{"execution_count":48,"output_type":"execute_result","data":{"text/plain":"(128,)"},"metadata":{}}]},{"cell_type":"code","source":"first_digest[:4]","metadata":{"execution":{"iopub.status.busy":"2024-03-19T11:24:29.050153Z","iopub.execute_input":"2024-03-19T11:24:29.050538Z","iopub.status.idle":"2024-03-19T11:24:29.065717Z","shell.execute_reply.started":"2024-03-19T11:24:29.050507Z","shell.execute_reply":"2024-03-19T11:24:29.064619Z"},"trusted":true},"execution_count":49,"outputs":[{"execution_count":49,"output_type":"execute_result","data":{"text/plain":"array([ 764644018, 1798380376, 1132963379, 3115479795], dtype=uint64)"},"metadata":{}}]},{"cell_type":"code","source":"lsh = datasketch.MinHashLSH(threshold=0.4, num_perm=num_perm)\nfor key in tqdm(min_dict.keys()):\n    lsh.insert(key,min_dict[key]) # insert minhash data structure","metadata":{"execution":{"iopub.status.busy":"2024-03-19T11:24:29.067506Z","iopub.execute_input":"2024-03-19T11:24:29.067951Z","iopub.status.idle":"2024-03-19T11:25:07.556332Z","shell.execute_reply.started":"2024-03-19T11:24:29.067916Z","shell.execute_reply":"2024-03-19T11:25:07.555065Z"},"trusted":true},"execution_count":50,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/242877 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1e365be03f814c239204ebea521823f4"}},"metadata":{}}]},{"cell_type":"code","source":"big_list = []\nfor query in min_dict.keys():\n    big_list.append(lsh.query(min_dict[query]))","metadata":{"execution":{"iopub.status.busy":"2024-03-19T11:25:07.559191Z","iopub.execute_input":"2024-03-19T11:25:07.560007Z","iopub.status.idle":"2024-03-19T11:25:32.573593Z","shell.execute_reply.started":"2024-03-19T11:25:07.559971Z","shell.execute_reply":"2024-03-19T11:25:32.572232Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"to_show = 3\nshowed = 0\nmax_count_per_cluster = 5\n\nfor i, elems in enumerate(big_list):\n    if len(elems) > 1:\n        cluster_texts = [norm_dict[key] for key in elems[:max_count_per_cluster]]\n        print(i)\n        print('\\n'.join(cluster_texts))\n        print('\\n', '=' * 30, '\\n')\n        showed += 1\n        if showed >= to_show:\n            break","metadata":{"execution":{"iopub.status.busy":"2024-03-19T11:34:42.612498Z","iopub.execute_input":"2024-03-19T11:34:42.612883Z","iopub.status.idle":"2024-03-19T11:34:42.621618Z","shell.execute_reply.started":"2024-03-19T11:34:42.612854Z","shell.execute_reply":"2024-03-19T11:34:42.619819Z"},"trusted":true},"execution_count":103,"outputs":[{"name":"stdout","text":"0\nчто было вних\nчто оставили потомкам....\nчто посеешь, то и пожнёшь.\nчто верно,то верно!:d\nто что и произходит.\n\n ============================== \n\n9\nспасибо, что вы есть, за тяжелый труд, храни вас господи\nкрасота..!! если есть, что показать??!! почему-нет!!???\n\n ============================== \n\n10\nцена? смесью продаётся?\nобувь 39,40 какая цена?\nцена? как можно купить?\nцена? объём?\nигрушки какая цена?\n\n ============================== \n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Dataset Quantization\n\nможно посмотреть реализацию тут:\n    \nhttps://github.com/magic-research/Dataset_Quantization/tree/main","metadata":{}},{"cell_type":"markdown","source":"Фрагмент реализации (сугубо для демонстрации):","metadata":{}},{"cell_type":"code","source":"import logging\n\nimport numpy as np\nfrom tqdm import tqdm\n\nfrom .submodular_function import GraphCut\nfrom .submodular_optimizer import NaiveGreedy\n\n\nclass DatasetReducer:\n    def __init__(self, ratio: float = 0.1, k: int = 10, verbose: bool = True):\n        \"\"\"\n        Dataset Quantization implementation\n        :param ratio: data keep ratio. ratio=0.1 means that ~10 of source dataset will be selected for new dataset\n        :param k: number of bins\n        :param verbose: either print method info or not\n        \"\"\"\n        self.ratio = ratio\n        self.k = k\n        self.verbose = verbose\n\n    @staticmethod\n    def _random_sample(data: list, n: int = 1000) -> list[int]:\n        indices = np.random.choice(len(data), n, replace=False)\n        return [data[i] for i in indices]\n\n    def quantize(self, embeddings: np.ndarray) -> list[int]:\n        \"\"\"\n        Get selected indices after dataset quantization\n        :param embeddings: 2d np.ndarray - embeddings of dataset items\n        :return: indices list of selected items\n        \"\"\"\n        n = int(embeddings.shape[0] * self.ratio)\n        bins_n = int(n / self.k)\n        budget_n = embeddings.shape[0] // self.k\n        if self.verbose:\n            logging.warning(f\"total: {embeddings.shape[0]} n: {n}, k: {self.k}, budget_n: {budget_n}, bins_n: {bins_n}\")\n        \n        indices = set(range(embeddings.shape[0]))\n        \n        sim_matrix = lambda a, b: embeddings[a] @ embeddings[b].T\n\n        # bin generation\n        bins = []\n        iterator = tqdm(range(self.k), desc='bins') if self.verbose else range(self.k)\n        for i in iterator:\n            submod_f = GraphCut(index=indices, similarity_kernel=sim_matrix)\n            submod_opt = NaiveGreedy(args=None, index=list(indices), budget=budget_n)\n            result_indices = submod_opt.select(\n                gain_function=submod_f.calc_gain,\n                update_state=submod_f.update_state,\n            )\n\n            bins.append(result_indices)\n\n            indices = indices - set(result_indices)\n\n        # bin sampling\n        index = []\n        for i in range(self.k):\n            sampled_indices = DatasetReducer._random_sample(bins[i], n=bins_n)\n            index.extend(sampled_indices)\n\n        return index\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\n\nfrom as_dq.embedder import Embedder\nfrom as_dq.quantizer import DatasetReducer\n\nrandom.seed(42)\n\nk = 10\nratio = 0.1\nbatch_size = 16\nembedder_path = '/Users/d.kalashnikov/Desktop/as_dq/e5-small'\n\ndata = ''.join([chr(32 + random.randint(0, 127 - 32)) for i in range(12000)]).split()\nprint('len(data): ', len(data))\n\nembeddings = Embedder(model_path=embedder_path, batch_size=16).calcucate(data)\nembeddings = np.concatenate(embeddings)\nprint('embeddings.shape: ', embeddings.shape)\n\nindex = DatasetReducer(ratio=ratio, k=6).quantize(embeddings)\n\nquantized_data = [data[ind] for ind in index]\nprint('len(quantized_data): ', len(quantized_data))\nprint('quantized_data:\\n', quantized_data)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}